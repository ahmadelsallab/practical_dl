{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"tensor_tutorial.ipynb","version":"0.3.2","provenance":[{"file_id":"1g5FCGBLmk11SJ0PD6G2m9NvyTobMYhLu","timestamp":1557141027334},{"file_id":"https://github.com/pytorch/tutorials/blob/gh-pages/_downloads/tensor_tutorial.ipynb","timestamp":1557138662894}]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"lvN2ev_WmpKB","colab_type":"code","colab":{}},"source":["%matplotlib inline"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XC7id4fvmpKN","colab_type":"text"},"source":["\n","What is PyTorch?\n","================\n","\n","It’s a Python-based scientific computing package targeted at two sets of\n","audiences:\n","\n","-  A replacement for NumPy to use the power of GPUs\n","-  a deep learning research platform that provides maximum flexibility\n","   and speed\n","\n","Getting Started\n","---------------\n","\n","Tensors\n","^^^^^^^\n","\n","Tensors are similar to NumPy’s ndarrays, with the addition being that\n","Tensors can also be used on a GPU to accelerate computing.\n","\n"]},{"cell_type":"code","metadata":{"id":"aFRy_-WJmpKO","colab_type":"code","colab":{}},"source":["from __future__ import print_function\n","import torch"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"19wtsskVmpKR","colab_type":"text"},"source":["Construct a 5x3 matrix, uninitialized:\n","\n"]},{"cell_type":"code","metadata":{"id":"zihiDvxcmpKS","colab_type":"code","outputId":"6b3b7f89-1202-49bc-9620-b79aaf02ece6","executionInfo":{"status":"ok","timestamp":1558604655572,"user_tz":-120,"elapsed":2619,"user":{"displayName":"Ahmad El Sallab","photoUrl":"","userId":"06251939449358079201"}},"colab":{"base_uri":"https://localhost:8080/","height":100}},"source":["x = torch.empty(5, 3)\n","print(x)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([[1.2291e-36, 0.0000e+00, 3.3631e-44],\n","        [0.0000e+00,        nan, 0.0000e+00],\n","        [1.1578e+27, 1.1362e+30, 7.1547e+22],\n","        [4.5828e+30, 1.2121e+04, 7.1846e+22],\n","        [9.2198e-39, 0.0000e+00, 0.0000e+00]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OqRJ_3Q7mpKU","colab_type":"text"},"source":["Construct a randomly initialized matrix:\n","\n"]},{"cell_type":"code","metadata":{"id":"zA2fjgy0mpKV","colab_type":"code","outputId":"f91e458b-853e-4f46-d2d5-4f978504ecc8","executionInfo":{"status":"ok","timestamp":1558604655574,"user_tz":-120,"elapsed":2620,"user":{"displayName":"Ahmad El Sallab","photoUrl":"","userId":"06251939449358079201"}},"colab":{"base_uri":"https://localhost:8080/","height":100}},"source":["x = torch.rand(5, 3)\n","print(x)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([[0.8131, 0.9760, 0.0250],\n","        [0.2526, 0.7598, 0.0531],\n","        [0.9447, 0.9461, 0.7815],\n","        [0.8422, 0.2225, 0.9818],\n","        [0.2587, 0.7995, 0.2109]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"22DIvgFhmpKX","colab_type":"text"},"source":["Construct a matrix filled zeros and of dtype long:\n","\n"]},{"cell_type":"code","metadata":{"id":"NWTTqLCAmpKZ","colab_type":"code","outputId":"7c6e0938-edad-42c7-ab88-e6f380491663","executionInfo":{"status":"ok","timestamp":1558604655575,"user_tz":-120,"elapsed":2620,"user":{"displayName":"Ahmad El Sallab","photoUrl":"","userId":"06251939449358079201"}},"colab":{"base_uri":"https://localhost:8080/","height":100}},"source":["x = torch.zeros(5, 3, dtype=torch.long)\n","print(x)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([[0, 0, 0],\n","        [0, 0, 0],\n","        [0, 0, 0],\n","        [0, 0, 0],\n","        [0, 0, 0]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9bZkQl4TmpKc","colab_type":"text"},"source":["Construct a tensor directly from data:\n","\n"]},{"cell_type":"code","metadata":{"id":"pY0nNcHtmpKc","colab_type":"code","outputId":"eaad5594-473a-44e9-e8db-d7596c0e6c50","executionInfo":{"status":"ok","timestamp":1558604655577,"user_tz":-120,"elapsed":2619,"user":{"displayName":"Ahmad El Sallab","photoUrl":"","userId":"06251939449358079201"}},"colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["x = torch.tensor([5.5, 3])\n","print(x)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([5.5000, 3.0000])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qQPAPi8BmpKg","colab_type":"text"},"source":["or create a tensor based on an existing tensor. These methods\n","will reuse properties of the input tensor, e.g. dtype, unless\n","new values are provided by user\n","\n"]},{"cell_type":"code","metadata":{"id":"ECSegiA6mpKi","colab_type":"code","outputId":"1cdd3b3d-6180-4989-c3ca-b1373c7ec3bf","executionInfo":{"status":"ok","timestamp":1558604655578,"user_tz":-120,"elapsed":2619,"user":{"displayName":"Ahmad El Sallab","photoUrl":"","userId":"06251939449358079201"}},"colab":{"base_uri":"https://localhost:8080/","height":184}},"source":["x = x.new_ones(5, 3, dtype=torch.double)      # new_* methods take in sizes\n","print(x)\n","\n","x = torch.randn_like(x, dtype=torch.float)    # override dtype!\n","print(x)                                      # result has the same size"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([[1., 1., 1.],\n","        [1., 1., 1.],\n","        [1., 1., 1.],\n","        [1., 1., 1.],\n","        [1., 1., 1.]], dtype=torch.float64)\n","tensor([[ 0.0198,  0.4131,  0.8526],\n","        [-2.2900,  0.4638, -0.2867],\n","        [ 0.4932, -0.7783, -0.7664],\n","        [ 0.2218, -0.1264,  0.6541],\n","        [ 0.7788,  0.1582,  2.1617]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"R-4Dv5QOmpKl","colab_type":"text"},"source":["Get its size:\n","\n"]},{"cell_type":"code","metadata":{"id":"PS0fNZVGmpKn","colab_type":"code","outputId":"66a4f2c6-a16b-45af-9f7f-5f185bc3ab2e","executionInfo":{"status":"ok","timestamp":1558604655579,"user_tz":-120,"elapsed":2619,"user":{"displayName":"Ahmad El Sallab","photoUrl":"","userId":"06251939449358079201"}},"colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["print(x.size())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([5, 3])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jxKLpx6pmpKs","colab_type":"text"},"source":["<div class=\"alert alert-info\"><h4>Note</h4><p>``torch.Size`` is in fact a tuple, so it supports all tuple operations.</p></div>\n","\n","Operations\n","^^^^^^^^^^\n","There are multiple syntaxes for operations. In the following\n","example, we will take a look at the addition operation.\n","\n","Addition: syntax 1\n","\n"]},{"cell_type":"code","metadata":{"id":"TQ9w_vRCmpKt","colab_type":"code","outputId":"886de45e-3078-4a2d-eff8-5026c7aee0b2","executionInfo":{"status":"ok","timestamp":1558604655580,"user_tz":-120,"elapsed":2618,"user":{"displayName":"Ahmad El Sallab","photoUrl":"","userId":"06251939449358079201"}},"colab":{"base_uri":"https://localhost:8080/","height":100}},"source":["y = torch.rand(5, 3)\n","print(x + y)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([[ 0.8880,  0.4535,  1.3966],\n","        [-1.4154,  1.0664,  0.6642],\n","        [ 1.1451, -0.1896, -0.6289],\n","        [ 1.1850,  0.7426,  1.6142],\n","        [ 1.7589,  0.8261,  2.6879]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xNr7OxUPmpKv","colab_type":"text"},"source":["Addition: syntax 2\n","\n"]},{"cell_type":"code","metadata":{"id":"jNG-0U2TmpKw","colab_type":"code","outputId":"7e1f42de-e366-4e27-ec25-774524a4bc6d","executionInfo":{"status":"ok","timestamp":1558604655581,"user_tz":-120,"elapsed":2618,"user":{"displayName":"Ahmad El Sallab","photoUrl":"","userId":"06251939449358079201"}},"colab":{"base_uri":"https://localhost:8080/","height":100}},"source":["print(torch.add(x, y))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([[ 0.8880,  0.4535,  1.3966],\n","        [-1.4154,  1.0664,  0.6642],\n","        [ 1.1451, -0.1896, -0.6289],\n","        [ 1.1850,  0.7426,  1.6142],\n","        [ 1.7589,  0.8261,  2.6879]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"be5McksampKz","colab_type":"text"},"source":["Addition: providing an output tensor as argument\n","\n"]},{"cell_type":"code","metadata":{"id":"f-jVrtUQmpK0","colab_type":"code","outputId":"f26323c1-d7b5-4f36-95c2-8e36279d63f8","executionInfo":{"status":"ok","timestamp":1558604655582,"user_tz":-120,"elapsed":2618,"user":{"displayName":"Ahmad El Sallab","photoUrl":"","userId":"06251939449358079201"}},"colab":{"base_uri":"https://localhost:8080/","height":100}},"source":["result = torch.empty(5, 3)\n","torch.add(x, y, out=result)\n","print(result)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([[ 0.8880,  0.4535,  1.3966],\n","        [-1.4154,  1.0664,  0.6642],\n","        [ 1.1451, -0.1896, -0.6289],\n","        [ 1.1850,  0.7426,  1.6142],\n","        [ 1.7589,  0.8261,  2.6879]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WdFGyLs1mpK2","colab_type":"text"},"source":["Addition: in-place\n","\n"]},{"cell_type":"code","metadata":{"id":"ZjVCUCLbmpK3","colab_type":"code","outputId":"45d49c2c-e050-47a6-ea1f-b871724efe6c","executionInfo":{"status":"ok","timestamp":1558604656015,"user_tz":-120,"elapsed":3050,"user":{"displayName":"Ahmad El Sallab","photoUrl":"","userId":"06251939449358079201"}},"colab":{"base_uri":"https://localhost:8080/","height":100}},"source":["# adds x to y\n","y.add_(x)\n","print(y)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([[ 0.8880,  0.4535,  1.3966],\n","        [-1.4154,  1.0664,  0.6642],\n","        [ 1.1451, -0.1896, -0.6289],\n","        [ 1.1850,  0.7426,  1.6142],\n","        [ 1.7589,  0.8261,  2.6879]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Efiua867mpK6","colab_type":"text"},"source":["<div class=\"alert alert-info\"><h4>Note</h4><p>Any operation that mutates a tensor in-place is post-fixed with an ``_``.\n","    For example: ``x.copy_(y)``, ``x.t_()``, will change ``x``.</p></div>\n","\n","You can use standard NumPy-like indexing with all bells and whistles!\n","\n"]},{"cell_type":"code","metadata":{"id":"Ci5SvJ1pmpK7","colab_type":"code","outputId":"b15dd498-548f-4288-8a57-8e0bd64c33d8","executionInfo":{"status":"ok","timestamp":1558604656019,"user_tz":-120,"elapsed":3053,"user":{"displayName":"Ahmad El Sallab","photoUrl":"","userId":"06251939449358079201"}},"colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["print(x[:, 1])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([ 0.4131,  0.4638, -0.7783, -0.1264,  0.1582])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LH6OTkn9mpK-","colab_type":"text"},"source":["Resizing: If you want to resize/reshape tensor, you can use ``torch.view``:\n","\n"]},{"cell_type":"code","metadata":{"id":"McFx5FaompK-","colab_type":"code","outputId":"aa00ce72-5d8d-4eb8-9f1a-ad400adce2b2","executionInfo":{"status":"ok","timestamp":1558604664777,"user_tz":-120,"elapsed":803,"user":{"displayName":"Ahmad El Sallab","photoUrl":"","userId":"06251939449358079201"}},"colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["x = torch.randn(4, 4)\n","y = x.view(16)\n","z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n","print(x.size(), y.size(), z.size())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ikHUz5AWE-Bv","colab_type":"code","outputId":"fd79fdbb-de6b-4037-a21b-473797f5d159","executionInfo":{"status":"ok","timestamp":1558604875306,"user_tz":-120,"elapsed":697,"user":{"displayName":"Ahmad El Sallab","photoUrl":"","userId":"06251939449358079201"}},"colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["x = torch.randn(2, 4, 3)\n","#x.transpose(0,1).shape\n","x.size()\n","x.transpose(0,2).shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([3, 4, 2])"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"markdown","metadata":{"id":"DXAZpG2KGQvs","colab_type":"text"},"source":["transpose only applies to 2 axis, while permute can be applied to all the axes at the same time.\n","For example"]},{"cell_type":"code","metadata":{"id":"4_xUtMUnGNdz","colab_type":"code","outputId":"b6d83ac9-afff-49cc-e069-1e419934c2b5","executionInfo":{"status":"ok","timestamp":1558605568031,"user_tz":-120,"elapsed":836,"user":{"displayName":"Ahmad El Sallab","photoUrl":"","userId":"06251939449358079201"}},"colab":{"base_uri":"https://localhost:8080/","height":67}},"source":["\n","\n","a = torch.rand(1,2,3,4)\n","print(a.transpose(0,3).transpose(1,2).size())\n","print(a.permute(3,2,1,0).size())# same as np.transpose\n","print(a.permute(2,3,1,0).size())# This not the same as reshape"],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([4, 3, 2, 1])\n","torch.Size([4, 3, 2, 1])\n","torch.Size([3, 4, 2, 1])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7oO2W2PPIFtF","colab_type":"code","outputId":"97361d73-94e0-4fd1-ae16-207caa4570cc","executionInfo":{"status":"ok","timestamp":1558605565784,"user_tz":-120,"elapsed":678,"user":{"displayName":"Ahmad El Sallab","photoUrl":"","userId":"06251939449358079201"}},"colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["a.transpose(0,3)\n","a.shape# See how a is not changed"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 2, 3, 4])"]},"metadata":{"tags":[]},"execution_count":49}]},{"cell_type":"markdown","metadata":{"id":"VgY85veqJATR","colab_type":"text"},"source":["when you call transpose(), PyTorch doesn't generate new tensor with new layout, it just modifies meta information in Tensor object so offset and stride are for new shape. The transposed tensor and original tensor are indeed sharing the memory!\n","\n","Here bytes are still allocated in one block of memory but the order of the elements is different!\n","\n","When you call contiguous(), it actually makes a copy of tensor so the order of elements would be same as if tensor of same shape created from scratch.\n","\n","Normally you don't need to worry about this. If PyTorch expects contiguous tensor but if its not then you will get RuntimeError: input is not contiguous and then you just add a call to contiguous()."]},{"cell_type":"code","metadata":{"id":"lKmBm8saIPc-","colab_type":"code","outputId":"cc2a9c1b-3e0d-40e0-e9c6-15e5a4c1b7e4","executionInfo":{"status":"ok","timestamp":1558605588205,"user_tz":-120,"elapsed":847,"user":{"displayName":"Ahmad El Sallab","photoUrl":"","userId":"06251939449358079201"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["print(a.transpose(0,3).contiguous().shape)\n","\n","a.shape"],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([4, 2, 3, 1])\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 2, 3, 4])"]},"metadata":{"tags":[]},"execution_count":52}]},{"cell_type":"markdown","metadata":{"id":"sI9y_kxumpLB","colab_type":"text"},"source":["If you have a one element tensor, use ``.item()`` to get the value as a\n","Python number\n","\n"]},{"cell_type":"code","metadata":{"id":"2lHQwf3ampLC","colab_type":"code","outputId":"915104b2-51ed-409b-edb0-3cff0f5f6683","executionInfo":{"status":"ok","timestamp":1558604656022,"user_tz":-120,"elapsed":3052,"user":{"displayName":"Ahmad El Sallab","photoUrl":"","userId":"06251939449358079201"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["x = torch.randn(1)\n","print(x)\n","print(x.item())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([-2.0151])\n","-2.015139579772949\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9Vr5-bxumpLH","colab_type":"text"},"source":["**Read later:**\n","\n","\n","  100+ Tensor operations, including transposing, indexing, slicing,\n","  mathematical operations, linear algebra, random numbers, etc.,\n","  are described\n","  `here <http://pytorch.org/docs/torch>`_.\n","\n","NumPy Bridge\n","------------\n","\n","Converting a Torch Tensor to a NumPy array and vice versa is a breeze.\n","\n","The Torch Tensor and NumPy array will share their underlying memory\n","locations, and changing one will change the other.\n","\n","Converting a Torch Tensor to a NumPy Array\n","^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","\n"]},{"cell_type":"code","metadata":{"id":"WwofMBAImpLJ","colab_type":"code","outputId":"aed125c6-de42-458d-e1c5-9b4cde878f9e","executionInfo":{"status":"ok","timestamp":1558604656023,"user_tz":-120,"elapsed":3051,"user":{"displayName":"Ahmad El Sallab","photoUrl":"","userId":"06251939449358079201"}},"colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["a = torch.ones(5)\n","print(a)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([1., 1., 1., 1., 1.])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LtHQNVHtmpLO","colab_type":"code","outputId":"fb597c03-3c80-419c-8179-04f5d7fa2bd8","executionInfo":{"status":"ok","timestamp":1558604656025,"user_tz":-120,"elapsed":3052,"user":{"displayName":"Ahmad El Sallab","photoUrl":"","userId":"06251939449358079201"}},"colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["b = a.numpy()\n","print(b)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[1. 1. 1. 1. 1.]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"eebTPHG8mpLQ","colab_type":"text"},"source":["See how the numpy array changed in value.\n","\n"]},{"cell_type":"code","metadata":{"id":"kSZUvKtimpLS","colab_type":"code","outputId":"a93f0392-e142-43ba-9839-5abe0cdbd9cd","executionInfo":{"status":"ok","timestamp":1558604656027,"user_tz":-120,"elapsed":3054,"user":{"displayName":"Ahmad El Sallab","photoUrl":"","userId":"06251939449358079201"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["a.add_(1)\n","print(a)\n","print(b)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([2., 2., 2., 2., 2.])\n","[2. 2. 2. 2. 2.]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wAwho9XWmpLV","colab_type":"text"},"source":["Converting NumPy Array to Torch Tensor\n","^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","See how changing the np array changed the Torch Tensor automatically\n","\n"]},{"cell_type":"code","metadata":{"id":"5-tc_9b3mpLW","colab_type":"code","outputId":"33865c05-66d8-4198-e374-b8294b490a76","executionInfo":{"status":"ok","timestamp":1558604656029,"user_tz":-120,"elapsed":3055,"user":{"displayName":"Ahmad El Sallab","photoUrl":"","userId":"06251939449358079201"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["import numpy as np\n","a = np.ones(5)\n","b = torch.from_numpy(a)\n","np.add(a, 1, out=a)\n","print(a)\n","print(b)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[2. 2. 2. 2. 2.]\n","tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dQISIEdDsYq7","colab_type":"text"},"source":["Convert to numpy array"]},{"cell_type":"code","metadata":{"id":"7lBHQn1vsBJN","colab_type":"code","outputId":"82b5470f-c2b2-4030-b24e-58817856a07b","executionInfo":{"status":"ok","timestamp":1558604656031,"user_tz":-120,"elapsed":3056,"user":{"displayName":"Ahmad El Sallab","photoUrl":"","userId":"06251939449358079201"}},"colab":{"base_uri":"https://localhost:8080/","height":150}},"source":["import numpy as np\n","x = torch.randn(4, 4)\n","x1 = np.array(x)\n","x1 += 1\n","print(x)\n","print(x1)# See how the two tensors are not linked"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([[ 1.5206,  1.9469, -1.7359,  1.6695],\n","        [ 1.6953, -0.9151,  1.2206,  0.0844],\n","        [-0.4851,  0.4263,  1.9474, -0.9403],\n","        [-0.7241,  0.1669, -0.8165,  0.4246]])\n","[[ 2.5206027   2.946856   -0.73586607  2.6695101 ]\n"," [ 2.695272    0.08494896  2.2206295   1.0843753 ]\n"," [ 0.51487714  1.4262674   2.9473774   0.05973274]\n"," [ 0.2759241   1.1669002   0.1835112   1.4246122 ]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-j6PUKsYmpLZ","colab_type":"text"},"source":["All the Tensors on the CPU except a CharTensor support converting to\n","NumPy and back.\n","\n","CUDA Tensors\n","------------\n","\n","Tensors can be moved onto any device using the ``.to`` method.\n","\n"]},{"cell_type":"code","metadata":{"id":"qkUXFsGbmpLb","colab_type":"code","outputId":"291d9ad5-48fa-4534-c8bd-ba21ac977c6a","executionInfo":{"status":"ok","timestamp":1558604663225,"user_tz":-120,"elapsed":10248,"user":{"displayName":"Ahmad El Sallab","photoUrl":"","userId":"06251939449358079201"}},"colab":{"base_uri":"https://localhost:8080/","height":150}},"source":["# let us run this cell only if CUDA is available\n","# We will use ``torch.device`` objects to move tensors in and out of GPU\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")          # a CUDA device object\n","    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n","    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n","    z = x + y\n","    print(z)\n","    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([[ 2.5206,  2.9469, -0.7359,  2.6695],\n","        [ 2.6953,  0.0849,  2.2206,  1.0844],\n","        [ 0.5149,  1.4263,  2.9474,  0.0597],\n","        [ 0.2759,  1.1669,  0.1835,  1.4246]], device='cuda:0')\n","tensor([[ 2.5206,  2.9469, -0.7359,  2.6695],\n","        [ 2.6953,  0.0849,  2.2206,  1.0844],\n","        [ 0.5149,  1.4263,  2.9474,  0.0597],\n","        [ 0.2759,  1.1669,  0.1835,  1.4246]], dtype=torch.float64)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bDklTTpD3Gcx","colab_type":"code","outputId":"99760257-12c9-445e-93a8-26b1e84fa12b","executionInfo":{"status":"ok","timestamp":1558604663229,"user_tz":-120,"elapsed":10252,"user":{"displayName":"Ahmad El Sallab","photoUrl":"","userId":"06251939449358079201"}},"colab":{"base_uri":"https://localhost:8080/","height":84}},"source":["x.cuda()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 1.5206,  1.9469, -1.7359,  1.6695],\n","        [ 1.6953, -0.9151,  1.2206,  0.0844],\n","        [-0.4851,  0.4263,  1.9474, -0.9403],\n","        [-0.7241,  0.1669, -0.8165,  0.4246]], device='cuda:0')"]},"metadata":{"tags":[]},"execution_count":22}]}]}