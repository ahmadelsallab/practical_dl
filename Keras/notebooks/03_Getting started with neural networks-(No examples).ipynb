{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"03_Getting started with neural networks-(No examples).ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"7AA87UzV72dS","colab_type":"text"},"cell_type":"markdown","source":["# Chapter 3: Getting started with neural networks\n","- NN Anatomy in depth\n","- DL Frameworks:\n","    - Why?\n","    - Levels of frameworks\n","- Setting up a DL machine (self-reading)\n","- Introduction to Keras\n","- Introduction to DL in cloud: Google Colab\n","- Example 1: Classifying movie reviews (Binary classification)\n","- Example 2: Classifying newswires (Multi-class classification)\n","- Example 3: Predicting house prices (Regression)"]},{"metadata":{"id":"uO298mrS72dT","colab_type":"text"},"cell_type":"markdown","source":["## Anatomy of neural network in depth:\n","Training a neural network revolves around the following\n","objects:\n","- Layers, which are combined into a network (or model)\n","- The input data and corresponding targets\n","- The loss function, which defines the feedback signal used for learning\n","- The optimizer, which determines how learning proceeds\n","\n","![03_1_Anatomy_NN.png](https://github.com/ahmadelsallab/practical_dl/blob/master/Keras/notebooks/imgs/03_1_Anatomy_NN.png?raw=true)\n","\n"]},{"metadata":{"id":"GjRt3M0872dV","colab_type":"text"},"cell_type":"markdown","source":["### 1. Data:\n","_Vector data (2D)_ simple vector data, stored in 2D tensors of shape `(samples, features)`.\n","\n","_Sequence data (3D)_ Sequence data, stored in 3D tensors of shape `(samples, timesteps, features)`\n","\n","_Image data (4D)_ Image data, stored in 4D tensors `(samples, channels, length, width)` or `(samples, length, width, channels)`, is usually processed by 2D convolution layers (_Conv2D_).\n","\n","_Video data (5D)_ tensors of shape (samples, frames, height, width, channels) or (samples, frames, channels, height, width)\n","samples could be the batch (size=batch_size)\n","\n","### Length-Width convention in Math and Image\n","Usually in Math and Linear algebra libraries like _numpy_ the 2D convention of a rectangle is `rows, cols`==> `width, length`.\n","In image libraries, like _opencv_, _PIL_, the convention is `cols, rows`==>`width, length`\n","\n","### 2. Model:\n","\n","### Layers: the building blocks of deep learning\n","A __layer__ is a data-processing module that takes as input one or more tensors and that outputs one or more tensors\n","Some layers are stateless, but more frequently layers have a _state_: the layer’s __weights__, one or several tensors learned with stochastic gradient descent, which together contain the network’s _knowledge_.\n","\n","#### Dense layers --> Vector data (2D)\n","simple vector data, stored in 2D tensors of shape `(samples, features)`, is often processed by densely connected layers, also called fully connected or dense layers (the _Dense_ class in Keras)\n","\n","#### Recurrent (LSTM) layers --> Sequence data (3D)\n","Sequence data, stored in 3D tensors of shape `(samples, timesteps, features)`, is typically processed by recurrent layers such as an _LSTM_ layer.\n","\n","#### Convolution (Conv2D) layers --> Image data (4D)    \n","Image data, stored in 4D tensors `(samples, channels, length, width)` or `(samples, length, width, channels)`, is usually processed by 2D convolution layers (_Conv2D_).\n","\n","\n","### Layers and Data compatibility \n","You can think of layers as the __LEGO__ bricks of deep learning, a metaphor that is made explicit by frameworks like Keras. Building deep-learning models in Keras is done by clipping together compatible layers to form useful data-transformation pipelines. The notion of layer compatibility here refers specifically to the fact that every layer will only accept input tensors of a certain shape and will return output tensors of a certain shape. Consider the following example:\n"]},{"metadata":{"id":"hoKAqvzg72dV","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras import layers\n","layer = layers.Dense(32, input_shape=(784,))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kI4i5Lht72da","colab_type":"text"},"cell_type":"markdown","source":["We’re creating a layer that will only accept as input 2D tensors where the first dimension\n","is 784 (axis 0, the batch dimension, is unspecified, and thus any value would be\n","accepted). This layer will return a tensor where the first dimension has been transformed\n","to be 32. Thus this layer can only be connected to a downstream layer that expects 32-\n","dimensional vectors as its input. \n","\n","__When using Keras, you don’t have to worry about\n","compatibility, because the layers you add to your models are dynamically built to\n","match the shape of the incoming layer__. \n","\n","For instance, suppose you write the following:"]},{"metadata":{"id":"lyxVUXdM72db","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras import models\n","from keras import layers\n","model = models.Sequential()\n","model.add(layers.Dense(32, input_shape=(784,)))\n","model.add(layers.Dense(32))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ty61bzwG72de","colab_type":"text"},"cell_type":"markdown","source":["__The second layer didn’t receive an input shape argument__—instead, it automatically\n","inferred its input shape as being the output shape of the layer that came before."]},{"metadata":{"id":"mid1LbrB72df","colab_type":"text"},"cell_type":"markdown","source":["### Models: network of layers\n","Model means a __network architecture__\n","\n","Using the above convention (which we will learn that is called sequential API), we can build stack of layers.\n","But soon we will need to handle complex topologies:\n","- Two-branch networks (Multi-inputs)\n","- Multihead networks (Multi-outputs)\n","- Multi-inputs, Multi-outputs\n","- Inception blocks (Applying multiple parallel convolution layers to the same input).\n","\n","The topology of a network defines a _hypothesis space_ or _space of possibilities_ for mapping input data to output\n","data.\n","\n","What you’ll then be searching for is a good set of values for the _weights_ tensors for that topology of layers.\n","\n","_Picking the right network architecture is more an art than a science_\n"]},{"metadata":{"id":"rdlOXYO272dg","colab_type":"text"},"cell_type":"markdown","source":["## 3. Loss function (objective function)\n","__The quantity that will be minimized during training. It represents a measure of success for the task at hand__\n","\n","### Choosing the right objective function for the right problem is extremely important\n","\n","your network will take any shortcut it can, to minimize the loss; so if the objective\n","doesn’t fully correlate with success for the task at hand, your network will end up\n","doing things you may not have wanted. Imagine a stupid, omnipotent AI trained via\n","SGD, with this poorly chosen objective function: “maximizing the average well-being\n","of all humans alive.” To make its job easier, this AI might choose to kill all humans\n","except a few and focus on the well-being of the remaining ones—because average\n","well-being isn’t affected by how many humans are left. That might not be what you\n","intended! Just remember that all neural networks you build will be just as ruthless in\n","lowering their loss function—so choose the objective wisely, or you’ll have to face\n","unintended side effects.\n","\n","### Common loss functions\n","- __binary crossentropy__ for a _two-class_ classification problem, \n","- __categorical crossentropy__ for a _many-class_ classification problem,\n","- __mean squared error__ for a _regression problem_\n","- _connectionist temporal classification (__CTC__)_ for a _sequence-learning problem_\n","\n","_Only when you’re working on truly new research problems will you have to develop your own objective functions_\n","\n","\n","### Multi-loss for multi-outputs\n","A neural network that has multiple outputs may have multiple loss functions (one per\n","output). But the gradient-descent process must be based on a single scalar loss value;\n","so, for multiloss networks, all losses are combined (via averaging) into a single scalar\n","quantity.\n","\n","## 4. Optimizer\n","__Determines how the network will be updated based on the loss function. It implements a specific variant of stochastic gradient descent (SGD)__\n","\n","### Common optimizers:\n","- __Adam__ the most commonly used.\n","- __RMSProp__\n","- __SGD__\n","- ...etc\n","\n","For each one, you have __hyperparameters__ to adjust. The most important one is the __learning rate__. We will talk later about learning rate setting in more details.\n","\n"," \n","__Loss functions and optimizers: keys to configuring the learning process__"]},{"metadata":{"id":"ScgIYRMP44nm","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"vzU-zcHM5BsA","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"weI1P4Qs72dg","colab_type":"text"},"cell_type":"markdown","source":["# Deep learning frameworks, why?\n","## GPUs drive the revolution in DL\n","![03_2_DL_GPU.png](https://github.com/ahmadelsallab/practical_dl/blob/master/Keras/notebooks/imgs/03_2_DL_GPU.png?raw=true)\n","\n"]},{"metadata":{"id":"Sag4swrw72dh","colab_type":"text"},"cell_type":"markdown","source":["## We need drivers for GPUs (CUDA)\n","![03_3_NVIDIA_CUDA_Stack.png](https://github.com/ahmadelsallab/practical_dl/blob/master/Keras/notebooks/imgs/03_3_NVIDIA_CUDA_Stack.png?raw=true)"]},{"metadata":{"id":"EYnyQbMk72dj","colab_type":"text"},"cell_type":"markdown","source":["## Properties of DL frameworks:\n","- Standard Interface, mostly Python\n","- GPU and CPU compiler \n","- Symbolic (auto) differentiation\n","- BLAS optimization\n"]},{"metadata":{"id":"pXcuIIzq72dj","colab_type":"text"},"cell_type":"markdown","source":["## Levels of frameworks:\n","### Low level \n","- Computations in general: Theano/Pytorch\n","- Optimizers and NN names are not known\n","- Framework calculates the gradients\n","- You program does the optimization and weights update\n","- Things like adaptive learning rates, momentum, early stopping..etc are done by you\n","- Good if you want to come up with your optimization technique\n","\n","### Mid level \n","- Optimization in general- TensorFlow/PyTorch\n","- NN names are not known (ConvNets, RNN,…etc are unknown)\n","- You choose the optimizer and objective\n","- You write your own input-output relation _Model_\n","- No control over internal programming of optimization technique\n","- Good if you want to come up with a new model, NN connections,..etc\n","\n","### High level\n","- Neural networks (Deep Learning): Keras, Caffee\n","- NN layers are known--> lstm, convolution, dense,…etc\n","- No control over the internal connections of layers\n","- Good to have mix and match of known layers\n"]},{"metadata":{"id":"7MENYDQu72dl","colab_type":"text"},"cell_type":"markdown","source":["# Introduction to Keras: applying the NN anatomy\n","__Revision of earlier MNIST example__\n","\n","1. __Data__ Define your training data: input tensors and target tensors.\n","\n"]},{"metadata":{"id":"Jmo2Hxcn72dm","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras.datasets import mnist\n","(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n","train_images = train_images.reshape((60000, 28 * 28))\n","train_images = train_images.astype('float32') / 255\n","test_images = test_images.reshape((10000, 28 * 28))\n","test_images = test_images.astype('float32') / 255"],"execution_count":0,"outputs":[]},{"metadata":{"id":"emBh1ZfY72do","colab_type":"text"},"cell_type":"markdown","source":["2. __Model__ Define a network of layers (or model ) that maps your inputs to your targets.\n","\n","There are two ways to define a model: \n","\n","__A. using the Sequential class__\n","\n","only for linear stacks of layers, which is the most common network architecture by far \n","\n","\n","\n","\n","As a refresher, here’s a two-layer model defined using the Sequential class (note\n","that we’re passing the expected shape of the input data to the first layer):\n"]},{"metadata":{"id":"eOEOGW0g72dq","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras import models\n","from keras import layers\n","model = models.Sequential()\n","model.add(layers.Dense(32, activation='relu', input_shape=(784,)))\n","model.add(layers.Dense(10, activation='softmax'))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"i554Hcc672dt","colab_type":"text"},"cell_type":"markdown","source":["__B. using Functional API__ \n","\n","for directed acyclic graphs of layers, which lets you build completely arbitrary architectures\n","\n","- Two-branch networks (Multi-inputs)\n","- Multihead networks (Multi-outputs)\n","- Multi-inputs, Multi-outputs\n","- Inception blocks (Applying multiple parallel convolution layers to the same input).\n","\n","And here’s the same model defined using the functional API:"]},{"metadata":{"id":"qfSF_e_072dv","colab_type":"code","colab":{}},"cell_type":"code","source":["input_tensor = layers.Input(shape=(784,))\n","x = layers.Dense(32, activation='relu')(input_tensor)\n","output_tensor = layers.Dense(10, activation='softmax')(x)\n","model = models.Model(inputs=input_tensor, outputs=output_tensor)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"y16sYfXW72dy","colab_type":"text"},"cell_type":"markdown","source":["## Numpy vs. Keras tensors:\n","In function API, you treat layers as functions, which takes Keras tensor and returns another Keras tensor.\n","Keras tensor is a __symbolic__ tensor. It means that it has no value _yet_. So if you try to print them you get a data structure specifying the name, shape, dimension, type,...\n"]},{"metadata":{"id":"HnOv4aeu72dz","colab_type":"code","outputId":"488de2b6-7c22-4606-e6c5-a312c2dbf1da","executionInfo":{"status":"ok","timestamp":1554023660829,"user_tz":-120,"elapsed":2641,"user":{"displayName":"Ahmad El Sallab","photoUrl":"","userId":"06251939449358079201"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["print(output_tensor)"],"execution_count":84,"outputs":[{"output_type":"stream","text":["Tensor(\"dense_37/Softmax:0\", shape=(?, 10), dtype=float32)\n"],"name":"stdout"}]},{"metadata":{"id":"Zcd44U4D72d2","colab_type":"text"},"cell_type":"markdown","source":["\n","This is different from Numpy tensors, which have immediate values. It also has shape, dimension, type."]},{"metadata":{"id":"JEVi9Jsa72d2","colab_type":"code","outputId":"294c71b4-2b52-4984-a948-ee24fbe68b78","executionInfo":{"status":"ok","timestamp":1554023660832,"user_tz":-120,"elapsed":2632,"user":{"displayName":"Ahmad El Sallab","photoUrl":"","userId":"06251939449358079201"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"cell_type":"code","source":["import numpy as np\n","x = np.array([[0., 2., 4.], [1., 3., 5.]])\n","print(x)"],"execution_count":85,"outputs":[{"output_type":"stream","text":["[[0. 2. 4.]\n"," [1. 3. 5.]]\n"],"name":"stdout"}]},{"metadata":{"id":"4ynrpxa072d5","colab_type":"text"},"cell_type":"markdown","source":["## Static (Symboloic) computation graph\n","__A model \n","You might wonder, why we need two types of tensors?\n","The answer is that, Keras is built of top of computation graph-based frameworks, like _TensorFlow_.\n","In such frameworks, you first define an _abstract_ computation graph that defines the path from input to output.\n","\n","That graph is _static_.\n","\n","\n","\n","__Other frameworks like _Pytorch_ do not need those two types are they are based on _Dynamic_ graphs__"]},{"metadata":{"id":"LxJRR0IC72d6","colab_type":"text"},"cell_type":"markdown","source":["__Once your model architecture is defined, it doesn’t matter whether you used a Sequential model or the functional API. All of the following steps are the same.__\n","\n","you can visualize your model using `model.summary`"]},{"metadata":{"id":"NJUnbFxc72d7","colab_type":"code","outputId":"a882842c-7f15-4db2-fc3d-ff8703c1718b","executionInfo":{"status":"ok","timestamp":1554023660835,"user_tz":-120,"elapsed":2623,"user":{"displayName":"Ahmad El Sallab","photoUrl":"","userId":"06251939449358079201"}},"colab":{"base_uri":"https://localhost:8080/","height":254}},"cell_type":"code","source":["model.summary()"],"execution_count":86,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_4 (InputLayer)         (None, 784)               0         \n","_________________________________________________________________\n","dense_36 (Dense)             (None, 32)                25120     \n","_________________________________________________________________\n","dense_37 (Dense)             (None, 10)                330       \n","=================================================================\n","Total params: 25,450\n","Trainable params: 25,450\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"MkDsOPXc72d-","colab_type":"text"},"cell_type":"markdown","source":["3. __Compile__ Configure the learning process by choosing a loss function, an optimizer, and some metrics to monitor.\n","\n","The learning process is configured in the compilation step, where you specify the\n","optimizer and loss function(s) that the model should use, as well as the metrics you\n","want to monitor during training. \n","\n","Here’s an example with a single loss function, which\n","is by far the most common case:"]},{"metadata":{"id":"TRBUYn4I72d-","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras import optimizers\n","model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n","                loss='mse',\n","                metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"LBResmaL72eB","colab_type":"text"},"cell_type":"markdown","source":["# Note!\n","model.compile has nothing to do with weights, i.e. it doesnot re-init the weights. It only changes the optimizer, loss, metrics. \n","It can be called several times after fit to change the lrate or even optimizer. \n","If you want to re-init weights, then re-build all layers, then call compile on them. But better to call keras.backend.clear_session() before.\n","Take care of the order of execution in ipython!"]},{"metadata":{"id":"59QRyx1c72eC","colab_type":"text"},"cell_type":"markdown","source":["4. __Fit__ Iterate on your training data by calling the fit() method of your model.\n","\n","__Your _Model_ is defined with symbolic tensors__\n","\n","__Your _Data_ is defined in Numpy tensors__\n","\n","Then you `fit()` your _Data_ to your _Model_ to train.\n","You can think of this step as if you substitute the symbols in the symbolic graph with actual values.\n","\n","`fit()` initiates the training loop.\n","\n","Here you need to define the training parameters:\n","- epochs\n","- batch_size\n","- validation_data\n","- checkpoints (learning schedule, early stopping, best model saving, tensorboard,...etc)"]},{"metadata":{"id":"382lI0PfNeoB","colab_type":"code","outputId":"a3f7b8d1-7f84-4d81-e0d3-c460232fc6c1","executionInfo":{"status":"ok","timestamp":1554023660838,"user_tz":-120,"elapsed":2606,"user":{"displayName":"Ahmad El Sallab","photoUrl":"","userId":"06251939449358079201"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"cell_type":"code","source":["from keras.utils import to_categorical\n","train_labels = to_categorical(train_labels)\n","print(train_labels.shape)\n","print(train_labels[0])"],"execution_count":88,"outputs":[{"output_type":"stream","text":["(60000, 10)\n","[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"],"name":"stdout"}]},{"metadata":{"id":"9sSjCDZ672eF","colab_type":"code","outputId":"bca4a629-20c9-4c71-b62e-0f7c95a5694d","executionInfo":{"status":"ok","timestamp":1554023667875,"user_tz":-120,"elapsed":9630,"user":{"displayName":"Ahmad El Sallab","photoUrl":"","userId":"06251939449358079201"}},"colab":{"base_uri":"https://localhost:8080/","height":217}},"cell_type":"code","source":["model.fit(train_images, train_labels, epochs=5, batch_size=128)"],"execution_count":89,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n","60000/60000 [==============================] - 2s 30us/step - loss: 0.0206 - acc: 0.8743\n","Epoch 2/5\n","60000/60000 [==============================] - 1s 22us/step - loss: 0.0109 - acc: 0.9310\n","Epoch 3/5\n","60000/60000 [==============================] - 1s 22us/step - loss: 0.0092 - acc: 0.9420\n","Epoch 4/5\n","60000/60000 [==============================] - 1s 22us/step - loss: 0.0081 - acc: 0.9485\n","Epoch 5/5\n","60000/60000 [==============================] - 1s 23us/step - loss: 0.0074 - acc: 0.9537\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f03af3b4e48>"]},"metadata":{"tags":[]},"execution_count":89}]},{"metadata":{"id":"CnbPhV6a72eH","colab_type":"text"},"cell_type":"markdown","source":["# Running Deep Learning models:\n","## Local mode: Setting up a deep-learning workstation\n","Self reading: section 3.3\n","    \n","## Colab(Tutorial TODO)"]},{"metadata":{"id":"HUPgytFn72eJ","colab_type":"text"},"cell_type":"markdown","source":["# <center>More Real Examples</center>"]},{"metadata":{"id":"YYCLb2sI72eJ","colab_type":"text"},"cell_type":"markdown","source":["# Example 1: Classifying movie reviews: a binary classification example"]},{"metadata":{"id":"VWrP2C_872eL","colab_type":"text"},"cell_type":"markdown","source":["## 1. Data\n","You’ll work with the IMDB dataset: a set of 50,000 highly polarized reviews from the\n","Internet Movie Database. They’re split into 25,000 reviews for training and 25,000\n","reviews for testing, each set consisting of 50% negative and 50% positive reviews.\n","\n","__Why use separate training and test sets?__\n","\n","Because you should never test a machinelearning\n","model on the same data that you used to train it! Just because a model performs\n","well on its training data doesn’t mean it will perform well on data it has never\n","seen; and what you care about is your model’s performance on new data (because you\n","already know the labels of your training data—obviously you don’t need your model\n","to predict those). For instance, it’s possible that your model could end up merely memorizing\n","a mapping between your training samples and their targets, which would be\n","useless for the task of predicting targets for data the model has never seen before.\n","We’ll go over this point in much more detail in the next chapter.\n","\n"]},{"metadata":{"id":"5RA7mUeL72eN","colab_type":"text"},"cell_type":"markdown","source":["## 1.1 Load data"]},{"metadata":{"id":"yYh71hUf72eP","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras.datasets import imdb\n","(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)# The argument num_words=10000 means you’ll only keep the top 10,000 most frequentlyoccurring words in the training data. Rare words will be discarded. This allows you to work with vector data of manageable size."],"execution_count":0,"outputs":[]},{"metadata":{"id":"5CqQ9cuJ72eT","colab_type":"text"},"cell_type":"markdown","source":["The variables `train_data` and `test_data` are lists of reviews; each review is a list of\n","word indices (encoding a sequence of words). train_labels and test_labels are lists of 0s and 1s, where 0 stands for negative and 1 stands for positive:"]},{"metadata":{"id":"AXfQA-Hs72eU","colab_type":"code","outputId":"41b6f00a-9c30-4f2d-aad3-3ec73e1a90e4","executionInfo":{"status":"ok","timestamp":1554023674969,"user_tz":-120,"elapsed":16695,"user":{"displayName":"Ahmad El Sallab","photoUrl":"","userId":"06251939449358079201"}},"colab":{"base_uri":"https://localhost:8080/","height":3981}},"cell_type":"code","source":["train_data[0]"],"execution_count":91,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1,\n"," 14,\n"," 22,\n"," 16,\n"," 43,\n"," 530,\n"," 973,\n"," 1622,\n"," 1385,\n"," 65,\n"," 458,\n"," 4468,\n"," 66,\n"," 3941,\n"," 4,\n"," 173,\n"," 36,\n"," 256,\n"," 5,\n"," 25,\n"," 100,\n"," 43,\n"," 838,\n"," 112,\n"," 50,\n"," 670,\n"," 2,\n"," 9,\n"," 35,\n"," 480,\n"," 284,\n"," 5,\n"," 150,\n"," 4,\n"," 172,\n"," 112,\n"," 167,\n"," 2,\n"," 336,\n"," 385,\n"," 39,\n"," 4,\n"," 172,\n"," 4536,\n"," 1111,\n"," 17,\n"," 546,\n"," 38,\n"," 13,\n"," 447,\n"," 4,\n"," 192,\n"," 50,\n"," 16,\n"," 6,\n"," 147,\n"," 2025,\n"," 19,\n"," 14,\n"," 22,\n"," 4,\n"," 1920,\n"," 4613,\n"," 469,\n"," 4,\n"," 22,\n"," 71,\n"," 87,\n"," 12,\n"," 16,\n"," 43,\n"," 530,\n"," 38,\n"," 76,\n"," 15,\n"," 13,\n"," 1247,\n"," 4,\n"," 22,\n"," 17,\n"," 515,\n"," 17,\n"," 12,\n"," 16,\n"," 626,\n"," 18,\n"," 2,\n"," 5,\n"," 62,\n"," 386,\n"," 12,\n"," 8,\n"," 316,\n"," 8,\n"," 106,\n"," 5,\n"," 4,\n"," 2223,\n"," 5244,\n"," 16,\n"," 480,\n"," 66,\n"," 3785,\n"," 33,\n"," 4,\n"," 130,\n"," 12,\n"," 16,\n"," 38,\n"," 619,\n"," 5,\n"," 25,\n"," 124,\n"," 51,\n"," 36,\n"," 135,\n"," 48,\n"," 25,\n"," 1415,\n"," 33,\n"," 6,\n"," 22,\n"," 12,\n"," 215,\n"," 28,\n"," 77,\n"," 52,\n"," 5,\n"," 14,\n"," 407,\n"," 16,\n"," 82,\n"," 2,\n"," 8,\n"," 4,\n"," 107,\n"," 117,\n"," 5952,\n"," 15,\n"," 256,\n"," 4,\n"," 2,\n"," 7,\n"," 3766,\n"," 5,\n"," 723,\n"," 36,\n"," 71,\n"," 43,\n"," 530,\n"," 476,\n"," 26,\n"," 400,\n"," 317,\n"," 46,\n"," 7,\n"," 4,\n"," 2,\n"," 1029,\n"," 13,\n"," 104,\n"," 88,\n"," 4,\n"," 381,\n"," 15,\n"," 297,\n"," 98,\n"," 32,\n"," 2071,\n"," 56,\n"," 26,\n"," 141,\n"," 6,\n"," 194,\n"," 7486,\n"," 18,\n"," 4,\n"," 226,\n"," 22,\n"," 21,\n"," 134,\n"," 476,\n"," 26,\n"," 480,\n"," 5,\n"," 144,\n"," 30,\n"," 5535,\n"," 18,\n"," 51,\n"," 36,\n"," 28,\n"," 224,\n"," 92,\n"," 25,\n"," 104,\n"," 4,\n"," 226,\n"," 65,\n"," 16,\n"," 38,\n"," 1334,\n"," 88,\n"," 12,\n"," 16,\n"," 283,\n"," 5,\n"," 16,\n"," 4472,\n"," 113,\n"," 103,\n"," 32,\n"," 15,\n"," 16,\n"," 5345,\n"," 19,\n"," 178,\n"," 32]"]},"metadata":{"tags":[]},"execution_count":91}]},{"metadata":{"id":"pNWd61OX72eW","colab_type":"code","outputId":"90e06b73-ab83-4d61-9a79-fa7d7e7ca099","executionInfo":{"status":"ok","timestamp":1554023674972,"user_tz":-120,"elapsed":16678,"user":{"displayName":"Ahmad El Sallab","photoUrl":"","userId":"06251939449358079201"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["train_labels[0]"],"execution_count":92,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{"tags":[]},"execution_count":92}]},{"metadata":{"id":"W3NNCi8M72eZ","colab_type":"text"},"cell_type":"markdown","source":["Because you’re restricting yourself to the top 10,000 most frequent words, no word\n","index will exceed 10,000:"]},{"metadata":{"id":"yqW5xKVq72ea","colab_type":"code","outputId":"ef47445b-5ba3-4d64-a59b-b7976785e483","executionInfo":{"status":"ok","timestamp":1554023674973,"user_tz":-120,"elapsed":16668,"user":{"displayName":"Ahmad El Sallab","photoUrl":"","userId":"06251939449358079201"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["max([max(sequence) for sequence in train_data])"],"execution_count":93,"outputs":[{"output_type":"execute_result","data":{"text/plain":["9999"]},"metadata":{"tags":[]},"execution_count":93}]},{"metadata":{"id":"Ga7w-3tH72ed","colab_type":"text"},"cell_type":"markdown","source":["### Sanity checks\n","For kicks, here’s how you can quickly decode one of these reviews back to English\n","words:"]},{"metadata":{"id":"Fw4Rmd_j72ee","colab_type":"code","colab":{}},"cell_type":"code","source":["word_index = imdb.get_word_index()\n","reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n","decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"SMxMQqoG72ej","colab_type":"text"},"cell_type":"markdown","source":["## 1.2 Prepare data (vectorize, binarize, digitize,...etc)"]},{"metadata":{"id":"Ca6Gzoe372el","colab_type":"text"},"cell_type":"markdown","source":["You can’t feed lists of integers into a neural network. You have to turn your lists into\n","tensors. There are two ways to do that:\n","\n","-  Pad your lists so that they all have the same length, turn them into an integer\n","tensor of shape (samples, word_indices), and then use as the first layer in\n","your network a layer capable of handling such integer tensors (the Embedding\n","layer, which we’ll cover in detail later in the book).\n","\n","- One-hot encode your lists to turn them into vectors of 0s and 1s. This would\n","mean, for instance, turning the sequence [3, 5] into a 10,000-dimensional vector\n","that would be all 0s except for indices 3 and 5, which would be 1s. Then you\n","could use as the first layer in your network a Dense layer, capable of handling\n","floating-point vector data.\n","\n","_We will use the latter one for simplicity, but you should have noticed that the order of words is mixed. This model is called Bag-of-words_"]},{"metadata":{"id":"MO8ePxrl72em","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","\n","def vectorize_sequences(sequences, dimension=10000):\n","    results = np.zeros((len(sequences), dimension))\n","    for i, sequence in enumerate(sequences):\n","        results[i, sequence] = 1.\n","    return results\n","\n","x_train = vectorize_sequences(train_data)\n","x_test = vectorize_sequences(test_data)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2D5b2Fho72ep","colab_type":"text"},"cell_type":"markdown","source":["Let's have a look on the data transformation:"]},{"metadata":{"id":"BORfDzxk-3Ck","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"2c95f571-32d7-4dd4-b2ea-f68dab6c4e28","executionInfo":{"status":"ok","timestamp":1554023679529,"user_tz":-120,"elapsed":21199,"user":{"displayName":"Ahmad El Sallab","photoUrl":"","userId":"06251939449358079201"}}},"cell_type":"code","source":["x_train.shape"],"execution_count":96,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(25000, 10000)"]},"metadata":{"tags":[]},"execution_count":96}]},{"metadata":{"id":"7JwKToS972ep","colab_type":"code","outputId":"52fce9d7-9fc7-4902-8245-73526417c970","executionInfo":{"status":"ok","timestamp":1554023679531,"user_tz":-120,"elapsed":21190,"user":{"displayName":"Ahmad El Sallab","photoUrl":"","userId":"06251939449358079201"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["x_train[0]"],"execution_count":97,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0., 1., 1., ..., 0., 0., 0.])"]},"metadata":{"tags":[]},"execution_count":97}]},{"metadata":{"id":"RgrQFa_c72et","colab_type":"text"},"cell_type":"markdown","source":["### Labels binarization\n","You should also vectorize your labels, which is straightforward for _binary classification_:"]},{"metadata":{"id":"ceEebH6q72eu","colab_type":"code","colab":{}},"cell_type":"code","source":["y_train = np.asarray(train_labels).astype('float32')\n","y_test = np.asarray(test_labels).astype('float32')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"IJItVJ3x72ew","colab_type":"text"},"cell_type":"markdown","source":["Now the data is ready to be fed into a neural network."]},{"metadata":{"id":"yfQwdawm72ey","colab_type":"text"},"cell_type":"markdown","source":["## 2. Model\n","Since the input is a 2D vector, then we choose `Dense` layers. Remeber, our choice of the BoW model.\n","For simplicity, we will be using the Sequential API.\n","\n","Let's choose the `relu` for activation function, which is the most widely used choice (Activation functions to be revisited later).\n","\n","The argument being passed to each Dense layer (16) is the number of hidden units of the layer. A _hidden unit_ is a dimension in the representation space of the layer."]},{"metadata":{"id":"NmtrVHLY72e0","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras import models\n","from keras import layers\n","model = models.Sequential()\n","model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Omiec_8t72e3","colab_type":"text"},"cell_type":"markdown","source":["You may remember from chapter 2 that each such Dense layer with a relu activation\n","implements the following chain of tensor operations `output = relu(dot(W, input) + b)`\n","\n","__Network Capacity = degrees of freedom__\n","Having 16 hidden units means the weight matrix W will have shape (input_dimension,\n","16): the dot product with W will project the input data onto a 16-dimensional representation\n","space (and then you’ll add the bias vector b and apply the relu operation). You\n","can intuitively understand the dimensionality of your representation space as “how\n","much freedom you’re allowing the network to have when learning internal representations.”\n","\n","__Capacity vs. Complexity__\n","Having more hidden units (a higher-dimensional representation space)\n","allows your network to learn more-complex representations, but it makes the network\n","more computationally expensive and may lead to learning unwanted patterns (patterns\n","that will improve performance on the training data but not on the test data).\n","\n","__Network architecture definition__\n","There are two key architecture decisions to be made about such a stack of Dense layers:\n","- How many layers to use\n","- How many hidden units to choose for each layer\n","\n","Now, to have a model, we need to have _Network of layers_. For the Sequential API, we can only do stack of layers.\n","In next lessons, you’ll learn formal principles to guide you in making these choices. For\n","the time being, you’ll have to trust me with the following architecture choice:\n","\n","- Two intermediate layers with 16 hidden units each\n","- A third layer that will output the scalar prediction regarding the sentiment of the current review\n","\n","![03_4_Simple_Model.png](https://github.com/ahmadelsallab/practical_dl/blob/master/Keras/notebooks/imgs/03_4_Simple_Model.png?raw=true)"]},{"metadata":{"id":"olox9qgy72e4","colab_type":"code","colab":{}},"cell_type":"code","source":["model.add(layers.Dense(16, activation='relu'))\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wEWG-cjU72e7","colab_type":"text"},"cell_type":"markdown","source":["![03_5_relul.png](https://github.com/ahmadelsallab/practical_dl/blob/master/Keras/notebooks/imgs/03_5_relu.png?raw=true)"]},{"metadata":{"id":"5GomHWx772e8","colab_type":"text"},"cell_type":"markdown","source":["The final layer will use a sigmoid activation so as to output a probability (a score between 0 and 1),indicating how likely the sample is to have the target “1”: how likely the review is to be\n","positive)."]},{"metadata":{"id":"Rs0TdF9p72e9","colab_type":"code","colab":{}},"cell_type":"code","source":["model.add(layers.Dense(1, activation='sigmoid'))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"R2D_qwT15ZvV","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"GnOpMHU-72e-","colab_type":"text"},"cell_type":"markdown","source":["![03_6_sigmoid.png](https://github.com/ahmadelsallab/practical_dl/blob/master/Keras/notebooks/imgs/03_6_sigmoid.png?raw=true)"]},{"metadata":{"id":"gTmMmRiw72e_","colab_type":"text"},"cell_type":"markdown","source":["__What are activation functions, and why are they necessary?__\n","\n","Without an activation function like relu (also called a non-linearity), the Dense layer\n","would consist of two linear operations—a dot product and an addition:\n","\n","`output = dot(W, input) + b`\n","\n","So the layer could only learn _linear transformations_ (affine transformations) of the\n","input data: the hypothesis space of the layer would be the set of all possible linear\n","transformations of the input data into a 16-dimensional space. \n","\n","Such a hypothesis space is too restricted and wouldn’t benefit from multiple layers of representations,\n","because a deep stack of linear layers would still implement a linear operation: \n","__adding more layers wouldn’t extend the hypothesis space.__\n","\n","In order to get access to a much richer hypothesis space that would benefit from\n","deep representations, you need a non-linearity, or activation function. _relu is the\n","most popular activation function in deep learning_, but there are many other candidates,\n","which all come with similarly strange names: _prelu, elu_, and so on."]},{"metadata":{"id":"RGx6Wrm772fA","colab_type":"text"},"cell_type":"markdown","source":["# 3. Compile\n","## loss \n","Because you’re facing a\n","binary classification problem and the output of your network is a probability (you end\n","your network with a single-unit layer with a sigmoid activation), it’s best to use the _binary_crossentropy_ loss. It isn’t the only viable choice: you could use, for instance,\n","_mean_squared_error_. \n","\n","_But crossentropy is usually the best choice when you’re dealing\n","with models that output probabilities._\n","\n","Crossentropy is a quantity from the field of _Information Theory_ that measures the distance between probability distributions or, in this case, between the ground-truth distribution and your predictions.\n","\n","## Optimizer\n","Let's use RMSProp\n","\n","## Complie\n","Here’s the step where you configure the model with the rmsprop optimizer and\n","the binary_crossentropy loss function. Note that you’ll also monitor accuracy\n","during training."]},{"metadata":{"id":"DZpHWMfn72fA","colab_type":"code","colab":{}},"cell_type":"code","source":["model.compile(optimizer='rmsprop',\n","                loss='binary_crossentropy',\n","                metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Y7s7-x6672fC","colab_type":"text"},"cell_type":"markdown","source":["__Another way of passing args to compile__\n","\n","You’re passing your optimizer, loss function, and metrics as strings, which is possible\n","because rmsprop, binary_crossentropy, and accuracy are packaged as part of Keras.\n","Sometimes you may want to configure the parameters of your optimizer or pass a custom\n","loss function or metric function. The former can be done by passing an optimizer\n","class instance as the optimizer argument,"]},{"metadata":{"id":"MwdqQc1D72fC","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras import optimizers\n","model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n","loss='binary_crossentropy',\n","metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"lmnE0TX472fF","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras import losses\n","from keras import metrics\n","model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n","loss=losses.binary_crossentropy,\n","metrics=[metrics.binary_accuracy])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_9-O6Qx872fH","colab_type":"text"},"cell_type":"markdown","source":["## Validation\n","In order to monitor during training the accuracy of the model on data it has never\n","seen before, you’ll create a validation set by setting apart 10,000 samples from the\n","original training data."]},{"metadata":{"id":"z7f1J37g72fR","colab_type":"code","colab":{}},"cell_type":"code","source":["x_val = x_train[:10000]\n","partial_x_train = x_train[10000:]\n","y_val = y_train[:10000]\n","partial_y_train = y_train[10000:]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tXZ6IbUM72fT","colab_type":"text"},"cell_type":"markdown","source":["# 4. Fit\n","\n","You’ll now train the model for 20 epochs (20 iterations over all samples in the\n","x_train and y_train tensors), in mini-batches of 512 samples. At the same time,\n","you’ll monitor loss and accuracy on the 10,000 samples that you set apart. You do so by\n","passing the validation data as the validation_data argument"]},{"metadata":{"id":"DXNxM7rD72fU","colab_type":"code","outputId":"d4c4b38b-e472-4379-f3ed-6aab45719887","executionInfo":{"status":"ok","timestamp":1554023728486,"user_tz":-120,"elapsed":70062,"user":{"displayName":"Ahmad El Sallab","photoUrl":"","userId":"06251939449358079201"}},"colab":{"base_uri":"https://localhost:8080/","height":783}},"cell_type":"code","source":["history = model.fit(partial_x_train,\n","                    partial_y_train,\n","                    epochs=20,\n","                    batch_size=512,\n","                    validation_data=(x_val, y_val))"],"execution_count":106,"outputs":[{"output_type":"stream","text":["Train on 15000 samples, validate on 10000 samples\n","Epoch 1/20\n","15000/15000 [==============================] - 3s 215us/step - loss: 0.5048 - binary_accuracy: 0.7871 - val_loss: 0.3774 - val_binary_accuracy: 0.8705\n","Epoch 2/20\n","15000/15000 [==============================] - 2s 156us/step - loss: 0.2991 - binary_accuracy: 0.9048 - val_loss: 0.3001 - val_binary_accuracy: 0.8897\n","Epoch 3/20\n","15000/15000 [==============================] - 2s 158us/step - loss: 0.2173 - binary_accuracy: 0.9283 - val_loss: 0.3082 - val_binary_accuracy: 0.8717\n","Epoch 4/20\n","15000/15000 [==============================] - 2s 157us/step - loss: 0.1747 - binary_accuracy: 0.9437 - val_loss: 0.2827 - val_binary_accuracy: 0.8844\n","Epoch 5/20\n","15000/15000 [==============================] - 2s 159us/step - loss: 0.1421 - binary_accuracy: 0.9539 - val_loss: 0.2856 - val_binary_accuracy: 0.8855\n","Epoch 6/20\n","15000/15000 [==============================] - 2s 158us/step - loss: 0.1148 - binary_accuracy: 0.9651 - val_loss: 0.3141 - val_binary_accuracy: 0.8777\n","Epoch 7/20\n","15000/15000 [==============================] - 2s 158us/step - loss: 0.0977 - binary_accuracy: 0.9708 - val_loss: 0.3131 - val_binary_accuracy: 0.8841\n","Epoch 8/20\n","15000/15000 [==============================] - 2s 158us/step - loss: 0.0805 - binary_accuracy: 0.9764 - val_loss: 0.3864 - val_binary_accuracy: 0.8653\n","Epoch 9/20\n","15000/15000 [==============================] - 2s 157us/step - loss: 0.0660 - binary_accuracy: 0.9820 - val_loss: 0.3642 - val_binary_accuracy: 0.8774\n","Epoch 10/20\n","15000/15000 [==============================] - 2s 157us/step - loss: 0.0559 - binary_accuracy: 0.9847 - val_loss: 0.3864 - val_binary_accuracy: 0.8778\n","Epoch 11/20\n","15000/15000 [==============================] - 2s 158us/step - loss: 0.0434 - binary_accuracy: 0.9901 - val_loss: 0.4181 - val_binary_accuracy: 0.8768\n","Epoch 12/20\n","15000/15000 [==============================] - 2s 158us/step - loss: 0.0379 - binary_accuracy: 0.9913 - val_loss: 0.4556 - val_binary_accuracy: 0.8698\n","Epoch 13/20\n","15000/15000 [==============================] - 2s 159us/step - loss: 0.0290 - binary_accuracy: 0.9941 - val_loss: 0.4719 - val_binary_accuracy: 0.8733\n","Epoch 14/20\n","15000/15000 [==============================] - 2s 158us/step - loss: 0.0257 - binary_accuracy: 0.9942 - val_loss: 0.5070 - val_binary_accuracy: 0.8714\n","Epoch 15/20\n","15000/15000 [==============================] - 2s 158us/step - loss: 0.0191 - binary_accuracy: 0.9968 - val_loss: 0.5340 - val_binary_accuracy: 0.8706\n","Epoch 16/20\n","15000/15000 [==============================] - 2s 162us/step - loss: 0.0146 - binary_accuracy: 0.9983 - val_loss: 0.5727 - val_binary_accuracy: 0.8691\n","Epoch 17/20\n","15000/15000 [==============================] - 2s 160us/step - loss: 0.0146 - binary_accuracy: 0.9977 - val_loss: 0.6020 - val_binary_accuracy: 0.8675\n","Epoch 18/20\n","15000/15000 [==============================] - 2s 158us/step - loss: 0.0090 - binary_accuracy: 0.9992 - val_loss: 0.6571 - val_binary_accuracy: 0.8642\n","Epoch 19/20\n","15000/15000 [==============================] - 2s 157us/step - loss: 0.0059 - binary_accuracy: 0.9998 - val_loss: 0.7417 - val_binary_accuracy: 0.8543\n","Epoch 20/20\n","15000/15000 [==============================] - 2s 155us/step - loss: 0.0057 - binary_accuracy: 0.9997 - val_loss: 0.7396 - val_binary_accuracy: 0.8592\n"],"name":"stdout"}]},{"metadata":{"id":"ckMXv84R72fX","colab_type":"text"},"cell_type":"markdown","source":["On CPU, this will take less than 2 seconds per epoch—training is over in 20 seconds.\n","At the end of every epoch, there is a slight pause as the model computes its loss and\n","accuracy on the 10,000 samples of the validation data."]},{"metadata":{"id":"itZC9Xe372fY","colab_type":"text"},"cell_type":"markdown","source":["## Plotting the loss\n","__History object__\n","\n","Note that the call to model.fit() returns a History object. This object has a member\n","history, which is a dictionary containing data about everything that happened\n","during training. Let’s look at it:"]},{"metadata":{"id":"AOKS9ySA72fZ","colab_type":"code","outputId":"267242f1-d804-4c60-b1dd-c120478f8944","executionInfo":{"status":"ok","timestamp":1554023728487,"user_tz":-120,"elapsed":70057,"user":{"displayName":"Ahmad El Sallab","photoUrl":"","userId":"06251939449358079201"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["history_dict = history.history\n","history_dict.keys()"],"execution_count":107,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['val_loss', 'val_binary_accuracy', 'loss', 'binary_accuracy'])"]},"metadata":{"tags":[]},"execution_count":107}]},{"metadata":{"id":"u4Z9aQXM72fe","colab_type":"text"},"cell_type":"markdown","source":["The dictionary contains four entries: one per metric that was being monitored during\n","training and during validation. In the following two listing, let’s use Matplotlib to plot\n","the training and validation loss side by side"]},{"metadata":{"id":"H6_zsYUo72fe","colab_type":"code","outputId":"4d18b5e7-f99f-49ae-a75b-f2990ab0f874","executionInfo":{"status":"ok","timestamp":1554023729214,"user_tz":-120,"elapsed":70774,"user":{"displayName":"Ahmad El Sallab","photoUrl":"","userId":"06251939449358079201"}},"colab":{"base_uri":"https://localhost:8080/","height":376}},"cell_type":"code","source":["import matplotlib.pyplot as plt\n","history_dict = history.history\n","loss_values = history_dict['loss']\n","val_loss_values = history_dict['val_loss']\n","epochs = range(1, len(val_loss_values) + 1)\n","plt.plot(epochs, loss_values, 'bo', label='Training loss')\n","plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n","plt.title('Training and validation loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()"],"execution_count":108,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAe8AAAFnCAYAAACPasF4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3XlcVPX+x/HXrCyCBgpumdcsM/Ga\n11av5QbkUmaWC1pa6S/NJZfUUq6GmZLlimZldTNtMayw5eaSS14rLS29lqaZWWblAiomsgwzc35/\nkBQJisIwC+/n48FDzpk553w+Mzif+Z7v93yPyTAMAxEREfEbZm8HICIiIudHxVtERMTPqHiLiIj4\nGRVvERERP6PiLSIi4mdUvEVERPyMirdUaklJSXTs2JGOHTsSExNDu3btCpezsrLOa18dO3YkIyPj\nrM+ZOXMmS5YsKUvI5e7ee+8lLS2tXPZ1xRVXcOjQIVavXs348ePLdLylS5cW/l6a17a0xo0bxzPP\nPFMu+xLxFqu3AxDxpscee6zw9/bt2/PUU09xzTXXXNC+Vq5cec7njB49+oL27W/i4+OJj4+/4O3T\n09N58cUX6dmzJ1C611akMlHLW+Qs+vbty+zZs+nUqRNbt24lIyODAQMG0LFjR9q3b8/ChQsLn3u6\n1fn555/Tq1cvZs6cSadOnWjfvj2bN28Girb62rdvzxtvvEH37t258cYbmTZtWuG+nnvuOVq2bMmd\nd97Ja6+9Rvv27YuN780336RTp07cfPPN3HXXXfzyyy8ApKWlMXz4cBITE+nQoQOdO3fmu+++A+DA\ngQP06NGDuLg4Ro8ejcvlOmO///3vf+nSpUuRdV27dmXDhg1nfQ1OS0tL49577z3n8dauXUuXLl3o\n0KEDd9xxB7t27QIgISGBX3/9lY4dO+JwOApfW4DFixfTuXNnOnbsyODBgzl27Fjhazt37lzuu+8+\n2rVrx3333UdOTk5Jby0Au3fvJiEhgY4dO9K1a1c+/vhjAE6dOsXQoUPp1KkTsbGxTJgwgfz8/BLX\ni1Q0FW+Rc9ixYwcffPABLVq04Nlnn+Xiiy9m5cqVLFq0iJkzZ3Lw4MEztvnmm2+46qqrWLFiBX36\n9OHZZ58tdt9btmwhNTWVt99+m1dffZVDhw7x3Xff8eKLL/Luu+/y+uuvl9jqPHr0KJMnT2bhwoV8\n+OGHXHLJJUVOB2/YsIE+ffqwatUqrr/+ehYtWgTAjBkzaNmyJWvWrOGee+5h69atZ+y7ZcuWHDp0\niAMHDgAFBfjQoUP885//LPVrcFpJx3M6nYwbN47HH3+cVatW0b59e5588kkAkpOTqV27NitXrsRu\ntxfu63//+x///ve/eeWVV1i5ciV16tRh5syZhY+vXLmS2bNns3r1ao4dO8bq1atLjMvtdvPQQw9x\n9913s3LlSqZMmcLo0aPJysrinXfeoWrVqqxYsYJVq1ZhsVjYu3dvietFKpqKt8g5tGnTBrO54L/K\nhAkTmDhxIgD16tUjKiqKn3/++YxtqlSpQlxcHAAxMTH8+uuvxe67S5cuWCwWatasSfXq1Tl48CBb\ntmzhuuuuIzo6mqCgIO68885it61evTpffvkltWrVAuCaa64pLLYADRs2pGnTpgA0adKksMB+8cUX\ndO7cGYBmzZpx6aWXnrFvu91Ou3btWLduHQBr1qwhLi4Oq9Va6tfgtJKOZ7Va2bhxI82bNy82/uKs\nX7+eDh06UL16dQB69OjBp59+Wvh4mzZtuOiii7BarTRq1OisXyp+/vlnMjIyuOWWWwD4+9//Tp06\ndfj666+JjIxk27ZtfPLJJ7jdbh577DGuvPLKEteLVDT1eYucQ7Vq1Qp///rrrwtbmmazmfT0dNxu\n9xnbhIeHF/5uNpuLfQ5AWFhY4e8WiwWXy8Vvv/1W5Jg1a9YsdluXy8XcuXNZt24dLpeLU6dO0aBB\ng2JjOL1vgBMnThQ5btWqVYvdf4cOHVi8eDH33HMPa9asYciQIef1Gpx2tuO98sorLFu2DIfDgcPh\nwGQylbgfgGPHjhEdHV1kX0ePHj1nziXtKzw8vMgxq1atyrFjx7jllls4ceIEKSkp7Nu3j9tuu43x\n48fTqVOnYtf/+eyASEVQy1vkPIwdO5YOHTqwatUqVq5cSURERLkfIywsjOzs7MLlI0eOFPu85cuX\ns27dOl599VVWrVrF8OHDS7X/qlWrFhlJf7rP+K9uuukmdu/ezY8//siPP/7IDTfcAJz/a1DS8bZu\n3coLL7zAs88+y6pVq5gyZco5Y69RowaZmZmFy5mZmdSoUeOc2xWnevXqnDhxgj/fmykzM7OwVZ+Q\nkMCbb77J8uXL2blzJ++8885Z14tUJBVvkfNw9OhRmjZtislkYtmyZeTk5BQptOWhWbNmfP755xw7\ndgyHw1FicTh69Ch169YlMjKS48ePs2LFCk6dOnXO/Tdv3rywL3jr1q389NNPxT7Pbrdz4403Mn36\ndGJjY7FYLIXHPZ/XoKTjHTt2jOrVq1OnTh1ycnJYtmwZ2dnZGIaB1WolOzsbp9NZZF9t27Zl9erV\nHD9+HIA33niDNm3anDPn4lx88cXUqlWL5cuXF8aWkZFBs2bNmD9/Pm+99RZQcObj4osvxmQylbhe\npKKpeIuchxEjRjB06FC6dOlCdnY2vXr1YuLEiSUWwAvRrFkzunXrRrdu3ejXrx/t2rUr9nm33nor\nmZmZxMfHM3r0aEaOHMmhQ4eKjFovztixY/noo4+Ii4vjtdde45///GeJz+3QoQNr1qyhU6dOhevO\n9zUo6Xg33XQT0dHRxMXF0b9/f+655x7Cw8MZPnw4V1xxBdWqVaNVq1ZFxgs0a9aMgQMHctddd9Gx\nY0dOnjzJqFGjzppvSUwmE7NmzeLVV1+lU6dOTJkyhZSUFEJDQ+natSvvvvsuHTp0oGPHjthsNrp2\n7VriepGKZtL9vEV8j2EYhS269evXM2fOHJ2eFZFCanmL+Jhjx45xww038Msvv2AYBitWrCgckS0i\nAmp5i/ikJUuW8NJLL2Eymbj00kuZOnVq4UAqEREVbxERET+j0+YiIiJ+RsVbRETEz/jNDGvp6Se9\nHUK5i4gI5fjx8r1G2NuUk/8IxLwCMScIzLyUU+lERYUXu14tby+yWi3eDqHcKSf/EYh5BWJOEJh5\nKaeyUfEWERHxMyreIiIifkbFW0RExM+oeIuIiPgZFW8RERE/o+ItIiLiZ1S8RURE/IzfTNLii+bN\nm8233+7i2LGj5ObmUqdOXapWrUZy8vRzbrt8+fvUqRNF8+Y3FPt4SspMevRIoE6duhcU27BhA3no\noYe59NLLLmh7ERHxXZWqeC9bZmXOHDt79php1MjNyJEOunVzXvD+HnxwFFBQiPft+55hw0aWetvO\nnbsQFRVe4sxxI0aMvuC4REQksFWa4r1smZVBg0IKl3ftsvy+nFOmAl6crVu/4I03XiU7O5thw0ax\nbduXrF+/FrfbTcuWrejffyD//vcCLr64FlFRdUlLW4rJZGb//h9o2zaW/v0HFracP/poLadOZfHT\nT/v55ZefGT58NC1btuLVV19mzZoPqVOnLk6nk4SEu2jR4pozYsnKymLq1ElkZZ3E6XQycuRYrrii\nMXPmTGf37l24XC66detO585dil0nIiK+p9IU7zlz7MWuT0mxl3vxBvj++70sWZKG3W5n27YveeaZ\nFzGbzfTs2ZVevfoUee433+zk9dffxu1206NHF/r3H1jk8SNHDjNjxlw++2wj7777NjExTUlLe5Ml\nS97m1KlTJCTcQULCXcXG8eabS4iJacrdd9/L7t3fMG/eLJKTp7Nx4ycsXfouTqeT5cvf57ffTpyx\nTkQkEH3xhZnNmy0EB0NIiEFICAQHGwQHU+y608tWH6qYPhSKZ+3ZU/zYvJLWl9Vll12O3V7whSE4\nOJhhwwZisVjIzMzkt99+K/LcK65oTHBwcIn7atasOQDR0dFkZWXx888HuPTShgQFBRMUFMyVV8aU\nuO3u3d/Qr98AABo3bsLPPx+gatVq1KtXn3HjHqJduzg6drwFu91+xjoRkUCzfbuZ224Lxek0nfe2\nVuvpAl9QzENC/lgODobGjWHSpIop8pWmeDdq5GbXrjMnjW/UyO2R49lsNgAOHTpIauprvPTSa4SG\nhtK3b88znmuxnH0y+z8/bhgGhgFm8x9fOkxn+Rs0mUwYhlG47HYX5Dtz5ly+/XY3q1evZOXKD5g9\ne36x60REAkVuLgwbFozTaeKJJ3KpXt0gNxeys03k5kJubsG/OTkmcnKKLv/539O/Hz1qKlzndpv4\n6isYPRoiIjyfS6Up3iNHOor0eZ82YoTDo8fNzMwkIiKC0NBQvv12N4cOHSI/P79M+6xduzb79n2P\n0+nk5MmT7N69q8TnNm7chG3bvqBp07+zY8fXNGjQkIMHf+WTTzbQo0cCV1zRmP797y52nYhIIJk2\nLYhvv7XQv7+DAQPK9jn8Z4YBDgfUrBlOZma57fasKk3xLujXziEl5Y/R5iNGlG20eWlcfnkjQkJC\nGTy4P3//e3O6dr2DmTOfpFmzqy54n5GR1YmP78j99/ejfv0GNGkSU2LrvWfP3iQnP8bw4Q/gdrt5\n6KFHqFEjih07trN27YfYbDZuueW2YteJiASKzz6z8OyzNho0cDNxYl657ttkgqAg+P2Ea4UwGX8+\np+rDSrqkyp+d7VKxc1m+/H3i4ztisVjo1y+BWbPmER1ds5wjPH9lyclXBWJOEJh5BWJOEJh5VWRO\nWVnQrl0VDhww8f772Vx7rWe6Sz2RU1RUeLHrK03LO9AcPXqUgQPvwWazc/PNHX2icIuI+KJJk4LY\nv9/M8OF5HivcFU3F20/17Xsvffve6+0wRER82tq1FhYvttOkiYuxYz07xqkiaW5zEREJSMePw8iR\nwdhsBk8/nUtQkLcjKj8q3iIiEpDGjw/m8GEzY8c6aNo0ME6Xn6biLSIiAee996ykpdm4+moXw4YF\nzuny01S8RUQkoBw+bOLhh4MICTGYPz/Hp6Y1LS8q3mUwaNB9Z0yQ8txzT7NkyavFPn/r1i+YMOFh\nAMaNe+iMx99+O5V//3tBicfbu/c7fvppPwBJSePJy8u90NDp3r0L2dnZF7y9iIgvMgwYPTqYY8fM\nPPpoHpde6hdXQ583jxbv5ORkevXqRUJCAl999VXh+sOHD9O3b9/Cn7Zt2/L++/53I4z4+A6sW7e6\nyLr169cRF3fzObedNm3WeR/vv/9dx4EDPwHw2GNPEBRU8nzoIiKV0ZIlVj780MpNNzm5777ym0XN\n13jsZMLmzZvZv38/qampfP/99yQmJpKamgpAzZo1eeWVVwBwOp307duX9u3beyoUj4mNvZnBgwcw\nZMhwAHbv3kVUVBRRUdFs2fI5L774HDabjfDwcCZPnlZk21tuiWXz5s188cVm5s6dSWRkdapXr1F4\ni8+pUyeRnn6EnJwc+vcfSK1atXn33TT++991RERE8Oij41m8OJWsrJM88cRk8vPzMZvNjBs3EZPJ\nxNSpk6hTpy57935Ho0ZXMG7cxGJzOHLk8BnbR0fXZPLkiRw9moHD4WDAgEFcc811Z6y74YZ/evw1\nFhEprZ9+MjFhQjDh4QZz5+ZiDuBzyx4r3ps2bSIuLg6Ahg0bcuLECbKysggLCyvyvGXLltGhQweq\nVKlSpuNNmhTE+++XbzpdujiZNKnkafQiIiKpU6cu33yzgyZNmrJu3Wri4zsCcPLkSZKSplCnTl0e\nf/xRPv98E6GhoWfsY8GCp5k48XEuv7wRY8YMp06dupw8+RvXXXcDnTrdyi+//MzEieN46aVXuf76\nlrRtG0uTJk0Lt3/xxee49dauxMbezEcfreGll55nwIBBfPvtLh57LJmIiEi6devMyZMnCQ8/c6ae\n4rbv0aM3J05kMn/+C5w8eZJNmz7l++/3nrFORMRXuN0wYkQwWVkm5s7NoW7dwDxdfprHvpdkZGQQ\n8adbq0RGRpKenn7G89588026d+/uqTA8Lj6+I2vXFpw6//TTDbRtGwvARRddxJNPTmHYsIFs2/Yl\nv/12otjtDx48yOWXNwKgefMWAISHV2XXrp0MHtyfqVMnlbgtwLff7uIf/7gagBYtruG7774FoG7d\nelSvXgOz2UyNGlGcOpVV6u3r1/8b2dmnePzxiWzduoW4uJuLXSci4itefNHGp59a6dgxn169PHvP\nCl9QYWPwiptCfdu2bVx66aVntMaLExERitVa8q0z588v+Clf9t9/SnbHHV2488476dGjGw0bXkrD\nhnUBeOqpKTz//PM0bNiQyZMnEx4ezEUXhRIUZCMqKhzT7/fxtFothXPXhobasVrhs8/W43DksHRp\nKpmZmXTv3p2oqHCCg21UqxZCVFQ4FouZGjXCsFotREZWISoqHMPIwWazEhlZpfA4BccwExERWmSO\n3LNtX69eFGlpb7N161aWLVvGl19+xhNPPFHsuuKUNBevPwvEnCAw8wrEnCAw8yqvnHbvhilToEYN\nWLTIRnR0Bd4h5C8q6n3yWPGOjo4mIyOjcPnIkSNERUUVec769etp2bJlqfZ3/Ljvjoz+298aMnfu\nfGJj4wsnpf/tt5PYbOHs2/crn366iTp16lOlSjZ5efmkp58s/DITGVmDL7/8mnr16vPJJxuJifk7\nBw4cIiIiiqNHT/Huu++Tm5tHevpJ8vKcHDuWRXr6SVwuNxkZWVx+eWNWr17/+xmADVx22RUcO3YK\np9NdGIvT6ebYsVMEBf0xYf7Ztv/kky38+OM+OnTozLBhYxgy5P+KXVfcBPy6gYL/CMS8AjEnCMy8\nyisnpxP69AklN9fCM8/kYDI5KeYkb4UIiBuTtGrVinnz5pGQkMDOnTuJjo4+o4X99ddf07lzZ0+F\nUGHi4zsyZUoSSUmPF667444eDB48gHr1LuGuu/rx0kvPM3DgkDO2HThwCBMmPEKtWrULby7Stm17\nxo17iG++2cEtt9xGdHQ0Cxe+wFVX/YM5c6YX6Tv/v/97gCeeeJz3338Hq9XG+PETcTpLf8qouO2D\ngoJZsGA+776bhtlspk+fvtSuXeeMdSIi3paSYmfbNgvdu+dz662Bf7r8NI/eEnTGjBl88cUXmEwm\nkpKS+OabbwgPDyc+Ph6ALl26sHDhQmrUqHHOfQXat07Qt2l/EYg5QWDmFYg5QWDmVR45ffWVmY4d\nQ4mKMtiw4RTVqpVTcBcoIFreAGPGjCmy3Lhx4yLL/nhtt4iIeF9uLgwbFozTaWLOnByvF+6KFsBX\nwYmISKB68skgdu+2cO+9Dtq1c3k7nAqn4i0iIn7ls88sPPOMjb/9zU1SUslzcQQyFW8REfEbWVnw\n4IPBmEzw9NM5lHF+L7+l4i0iIn7jsceC2L/fzNChDq67LrDu0X0+VLxFRMQvrFtnYdEiO1de6eLh\nhwPvHt3nQ8VbRER8XmYmjBwZjM1m8PTTuQQFeTsi71LxFhERnzd+fDCHDpkZM8bB3/9eeU+Xn6bi\nLSIiPu399628/baNq6928eCDlft0+Wkq3iIi4rMOHzYxdmwQISEG8+blYK2w22n5Nr0MIiLikwwD\nxowJ5tgxM1On5nLZZYF9j+7zoZa3iIj4HMOAyZODWLXKyo03OhkwIN/bIfkUtbxFRMSnuN0wfnwQ\nCxfaadjQzTPP5GJWU7MIFW8REfEZTieMGhVMaqqNJk1cLF2aQ3S0Tpf/lYq3iIj4BIcDBg8O5v33\nbbRo4WLJkmwiIrwdlW9S8RYREa/LyYEBA0JYs8ZKy5ZOXnsth7Awb0flu9SLICIiXpWVBXfdVVC4\n27d3smSJCve5qOUtIiJek5kJvXuH8uWXFjp3zmfBAk19WhpqeYuIiFdkZJi4446Cwt29ez4vvqjC\nXVoq3iIiUuF++QW6dg1hxw4L/fo5ePrpXM2edh5UvEVEpELt32/ippvgu+8sPPCAg+nT83Qd93nS\n9xwREakwe/eauPPOUA4ehDFj8hg71oHJ5O2o/I+Kt4iIVIidO8306BFCRoaZ6dPhnnt0h7ALpRMV\nIiLicVu3munWLZSMDDNPPpnLmDHejsi/qeUtIiIetXGjhbvuCiEnB+bNy6FXLycQ7O2w/JqKt4iI\neMy6dRbuvTcElwteeCGXLl2c3g4pIOi0uYiIeMR//mOlb98QABYvzlHhLkcq3iIiUu7efNPK/fcH\nY7fDkiU5xMa6vB1SQFHxFhGRcrVokY1hw4IJC4O33sqmVSsV7vLm0T7v5ORktm/fjslkIjExkWbN\nmhU+dvDgQR566CHy8/Np0qQJkydP9mQoIiJSAZ591kZSUjA1arhZujSHpk3d3g4pIHms5b1582b2\n799PamoqU6dOZerUqUUenzZtGv379+ett97CYrHw66+/eioUERHxMMOAGTPsJCUFU7u2m3ffVeH2\nJI8V702bNhEXFwdAw4YNOXHiBFlZWQC43W6+/PJL2rdvD0BSUhJ16tTxVCgiIuJB339vYtCgYJ56\nKohLLnHz3nvZXH65Crcneax4Z2RkEBERUbgcGRlJeno6AMeOHaNKlSo88cQT9O7dm5kzZ3oqDBER\n8ZAffzQxfHgwrVpV4Z13bFx1lYv338+mfn3D26EFvAq7ztswjCK/Hz58mH79+lG3bl0GDhzI+vXr\nadu2bYnbR0SEYrVaKiDSihUVFe7tEMqdcvIfgZhXIOYEvpXX/v0wZQosXAguF8TEwGOPQbduFszm\nsFLvx5dyKi8VlZPHind0dDQZGRmFy0eOHCEqKgqAiIgI6tSpwyWXXAJAy5Yt+e67785avI8fz/ZU\nqF4TFRVOevpJb4dRrpST/wjEvAIxJ/CdvH75xcScOXZef91Gfr6Jyy93MXasg9tuc2I2w9Gjpd+X\nr+RUnjyRU0lfBjx22rxVq1asWrUKgJ07dxIdHU1YWME3MqvVSr169fjxxx8LH2/QoIGnQhERkTI4\ndMjE+PFBXH99FRYtslOvnsEzz+SwYUM2t9/u1O08vcBjLe8WLVoQExNDQkICJpOJpKQk0tLSCA8P\nJz4+nsTERMaNG4dhGDRq1Khw8JqIiPiGI0dMzJtnZ9EiG7m5Ji65xM2YMbl07+7Eqsm1vcqjL/+Y\nv9w2pnHjxoW/169fnyVLlnjy8CIicgEyMkzMn2/npZds5OSYuPhiNw89lEevXvnYbN6OTkA3JhER\nkd8dOwbPPmvnhRfsZGebqF3bzWOP5dGnTz52u7ejkz9T8RYRqeROnCgo2s8/bycry0R0tJsJE/K4\n++58gnXnTp+k4i0iUkmdPAnPP2/n2Wft/PabiRo13Dz8cB733JNPSIi3o5OzUfEWEalksrLg3/+2\n88wzdo4fNxEZ6ebRR/O47758qlTxdnRSGireIiKVyIoVVsaODeLIETMXXWTwr3/lMWCAg7DSz60i\nPkDFW0SkEjh2DBITg0lLs2G3G4wencfgwQ6qVvV2ZHIhVLxFRALcihVWxowJIj3dTIsWLlJScrni\nCt04xJ+peIuIBKjjxwta22+/XdDanjAhjyFDHJpgJQDoLRQRCUArV1oYMyaYI0fM/OMfLubOVWs7\nkKh4i4gEkOPH4V//Cuatt9TaDmR6O0VEAsSqVRZGj/6jtZ2SkkvjxmptByIVbxERP5eZWdDafvNN\ntbYrC721IiJ+bNWqgr7tw4fNNG9e0Let1nbgU/EWEfFDmZkwYUIwS5cWtLb/9a88hg5Va7uy0Nss\nIuJnPvywoG/7dGs7JSWXK69Ua7syUfEWEfETf25t22wGiYl5DBum1nZlpLdcRMQPrF5d0No+dMjM\nVVcV9G2rtV15mb0dgIiIlOzECbj3XrjrrlCOHjUxfnwey5dnq3BXcmp5i4j4oNxceOMNG7Nm2Tl0\nCLW2pQgVbxERH3LiBLz8sp3nn7eRnm4mKMjg8cehf/9sbDZvRye+QsVbRMQHHDpkYsECO4sW2cjK\nMhEebjB8eB73359P06ZhpKd7O0LxJSreIiJetG+fifnz7aSm2nA4TERHuxk1ysE99+he21IyFW8R\nES/43//MzJtn5z//sWIYJho0cDN0aB49e+YTHOzt6MTXqXiLiFQQw4ANGyzMnWvn448LPn6vusrF\ngw86uOUWJxaLlwMUv6HiLSLiYS4XfPCBlblz7Xz1VUGFvukmJ8OHO2jd2oXJ5OUAxe+oeIuIeEhu\nLixdamP+fDs//GDGZDLo0iWfBx900Ly5LvmSC6fiLSJSzn777Y/LvY4cMWO3G/Tt62DIEAcNGxre\nDk8CQKUr3suWWZkzx86ePWYaNXIzcqSDbt2c3g5LRALA4cMmnn/exssv2zl50kRYmMGwYXkMGpRP\nzZoq2lJ+PFq8k5OT2b59OyaTicTERJo1a1b4WPv27alVqxaW30dozJgxg5o1a3oyHJYtszJoUEjh\n8q5dlt+Xc1TAReSCnTwJTz0VxMsv28jLMxEV5WbEiILLvapV83Z0Eog8Vrw3b97M/v37SU1N5fvv\nvycxMZHU1NQiz3nhhReoUqWKp0I4w5w59mLXp6TYVbxF5LwZRkGjICkpiMOHzVxyiZsHH8yjVy9d\n7iWe5bHivWnTJuLi4gBo2LAhJ06cICsri7CwME8d8pz27Cn+PiwlrRcRKcmePWbGjQvik0+sBAcb\nPPJIHkOHOlS0pUJ4rGplZGQQERFRuBwZGUn6X+b3S0pKonfv3syYMQPD8Hx/UKNGxY/uLGm9iMhf\nnToFjz9up127UD75xEp8vJMNG04xerQKt1ScChuw9tfiPHz4cG666SaqVavG0KFDWbVqFR07dixx\n+4iIUKzWss1g8Oij0Lv3mesnTrQQFRVepn1fKG8d15OUk/8IxLw8lZNhwDvvwMiR8NNPUL8+pKTA\nbbdZMZk8f0ZR75V/qKicPFa8o6OjycjIKFw+cuQIUVFRhcu333574e+tW7dmz549Zy3ex49nlzmm\n2FhYsMBKSsofo81HjHAQG+v0yqT/UVHhpKefrPgDe5By8h+BmJencvrhBxOJicGsXWvFZjMYOdLB\nyJEOQkPhTx9zHqP3yj94IqeSvgx47LR5q1atWLVqFQA7d+4kOjq6sL/75MmTDBgwAIfDAcCWLVu4\n/PLLPRVKEd26OVm/Pptff80gPFs0AAAgAElEQVRi/fpsDVQTkRLl5sL06XZat67C2rVWWrd28t//\nniIxsaBwi3iLx1reLVq0ICYmhoSEBEwmE0lJSaSlpREeHk58fDytW7emV69eBAUF0aRJk7O2ukVE\nKtratRbGjw/mxx/N1KrlZvLkXLp2dWoqU/EJJqMiRoqVg0A7vQI6beQvAjEnCMy8yiOnn382MWFC\nEMuX27BYDO6/P5+HH87DixfK6L3yExV52rzSzbAmIlIchwOee87OrFl2srNNXH+9kyefzKNJE12N\nIr5HxVtEKr1PPrEwblwQe/ZYqFHDzbRpufTqpVPk4rtUvEWk0jp82ERSUhBpaTZMJoN773WQmJjH\nRRd5OzKRs1PxFpFKx+mEl16y8eSTQZw8aeIf/3Dx5JO5uk2n+A0VbxGpFPLz4YsvLKxbZ+GDD6zs\n3WvhoosMpk/P5e6787GUbQ4okQql4i0iAeuXX0ysW2dl3ToLGzZYOXmyoBPbbjfo08fBhAkOatTw\niwtuRIpQ8RaRgJGXBxs2WAoL9u7dfzSn69d306NHPu3bO2nVykUF3tBQpNypeIuIX9u/38TatVY+\n+sjKJ5/AqVMFU58FBxvExjpp395JbKyTBg0MjR6XgKHiLSJ+JScHNm0qaF2vXWvl++//mOX5iiug\nbVsH7do5adnSRUiIFwMV8SAVbxHxaYYB+/aZCov1xo0WcnMLmtChoQYdO+bTrp2L9u2dXHNNGOnp\neV6OWMTzVLxFxCcZBqSmWpk1K4gff/yjdX3llS7atXMRG+vkuutcBAV5MUgRL1HxFhGf89NPJsaM\nCWb9eiuhoQa33ppP+/YFres6dTQ6XETFW0R8hssFCxfamDIliOxsE+3bO5k+PZd69VSwRf5MxVtE\nfMKePWZGjgzmiy8sREQYPPVUDj16aH5xkeKoeIuIV+Xnw9NP25k5047DYaJr13ymTs0jOlqtbZGS\nqHiLiNds325mxIhgvvnGQs2abp58MpfOnZ3eDkvE56l4i0iFy8mB6dPtPPOMHbfbxN13O0hKyqNa\nNW9HJuIfVLxFpEJt3Ghh1KhgfvjBTP36bmbOzKF1a5e3wxLxKyreIlIhfvsNJk8OYvFiO2azwQMP\nOHjkkTzNMS5yAVS8RcTjVq+2MGZMMAcPmmnc2MXs2blcfbXunS1yoVS8RcRjMjJMTJgQRFqaDZvN\nYOzYPEaMcGC3ezsyEf+m4i0i5c4wYNkyK//6VxBHj5pp0aKgtX3llWpti5QHFW8RKVe//mri4YeD\n+fBDKyEhBpMn53L//flYLOfeVkRKR8VbRMqF2w2LF9uYPDmIrCwTN93kZObMXP72N022IlLeVLxF\npMy2bDEzaVIwW7ZYqFrVYPbsXPr0ydfUpiIeouItIhds3z4TU6YE8Z//2AC49dZ8kpPzqFVLrW0R\nT1LxFpHzlpFhYuZMO4sW2XA6TVx9tYukpDxuuEGTrYhUBBVvESm17Gx4/nk7c+faycoy0aCBmwkT\ncrn1Vt39S6QiebR4Jycns337dkwmE4mJiTRr1uyM58ycOZP//e9/vPLKK54MRUTKwOWC1FQr06YF\nceiQmerV3fzrX3n07Zuva7ZFvMBjxXvz5s3s37+f1NRUvv/+exITE0lNTS3ynL1797JlyxZsNpun\nwhCRMjAMWLfOwuTJQezaZSE42GDkyDyGDXNQtaq3oxOpvMye2vGmTZuIi4sDoGHDhpw4cYKsrKwi\nz5k2bRqjRo3yVAgiUgZffWWme/cQevcOZfduM7175/PZZ6dITFThFvE2j7W8MzIyiImJKVyOjIwk\nPT2dsLAwANLS0rjuuuuoW7eup0IQkQvw008mnngiiLffLjgjFhvrZOLEPJo00exoIr6iVMV7x44d\npKen065dO2bPns3//vc/HnzwQa655ppSH8gw/rh0JDMzk7S0NBYuXMjhw4dLtX1ERChWa+BN0RQV\nFe7tEMqdcvIff87r+HFIToa5c8HhgH/8A6ZPh9hYK/40trUyvFeBQjlduFL9j5wyZQrTpk3jiy++\n4Ouvv2bixIlMnjyZxYsXl7hNdHQ0GRkZhctHjhwhKioKgM8++4xjx45x11134XA4+Omnn0hOTiYx\nMbHE/R0/nl3anPxGVFQ46eknvR1GuVJO/uN0Xnl58NJLNmbPDiIz08TFF7tJTMzjjjucmM2Qnu7t\nSEsv0N+rQKKcSr/P4pSqzzsoKIi//e1vrF27lp49e3LZZZdhNp9901atWrFq1SoAdu7cSXR0dOEp\n844dO7J8+XKWLl3K008/TUxMzFkLt4iUP7cb0tKstGpVhaSkYAwDkpJy2bjxFN27FxRuEfFNpWp5\n5+TksGLFCtasWcPQoUPJzMzkt99+O+s2LVq0ICYmhoSEBEwmE0lJSaSlpREeHk58fHy5BC/iSw4e\nNJGTA5de6tuzixkGfPyxhSeegC+/DMFuN3jgAQejRuUREeHt6ESkNEzGnzujS/DZZ5+xePFibr31\nVjp37sy8efOoX78+t912W0XECBBwp1dAp438RWlyOnDAxM03h3L0qJlrr3XRp08+Xbvm8/vJJp9w\n+LCJpUttLFliZe/egvEjd9yRz/jxedSv79tfOEorEP/+IDDzUk6l32dxStXyvuGGG2jatClhYWFk\nZGTQsmVLWrRoUa4Bivir3Fzo3z+Eo0fNXHWViy++MLNlSzD/+lcQt9+eT+/eTq67zuWVGcjy82H1\naitLlthYs8aCy2UiKMj4vWjbqF8/t+KDEpEyK1Xxfvzxx2ncuDHx8fEkJCTQtGlT3nvvPSZPnuzp\n+ER8mmHAI48Es327hT59HMyencfPP5t44w0bb7xh4/XX7bz+up3LLnPRu7eTnj3zqVnT863cb781\n8/rrNt5800pGRkHn9VVXuejdO5877sjnoosgKsrmV4PRROQPpRqS8s0339CjRw9WrFhBt27dmDNn\nDvv37/d0bB7z9ddmbrihChs2BN6lZ1KxFi+2sWSJjebNXUyblofJBPXqGYwd62DLllO8+WY2d9yR\nz4EDZh5/PIjmzavQr18wK1ZYyc8v31hOnoRXXrHRqVMoN91UhWefteNymRg40MG6dadYvTqb/v0L\nCreI+LdStbxPd4uvX7+ekSNHAuBwODwXlYeFhBgcOGDigQeCWbcuW7cvlAvyxRdmEhODqF7dzUsv\n5RAcXPRxsxnatHHRpo2L48chLa2g0K9cWfATFeWmZ08nffrkc/nlFzYBimHApk0WXn/dxvvvW8nJ\nMWE2G8TGFuz35pudBAWVQ7Ii4lNK1fJu0KABnTt35tSpU1x55ZW88847VKtWzdOxecxllxlMmpRH\nRoaZBx4Ixun0dkTib44cMdG/fwguFyxYkMvFF5/9C2BEBAwYkM+aNdmsXXuK//s/B/n5JubPt9Oq\nVRVuuSWU11+38pcZhEv0668mZs+2c/31Vbj99lCWLrURHW0wfnweW7eeYsmSHLp0UeEWCVSlGm3u\ncrnYs2cPDRs2xG63s2PHDi655BKqVuAEx+U9gs8w4L77glm+3MZDD+UxblzFn0nQaEv/8Nec8vOh\ne/cQNm2y8uijuQwbdmHnv3NzYeVKK6+9ZmPDBguGYSI01ChxkFteHnz4YcHz16+34HabCAkx6NKl\noJV9ww2u87o2uzK8V4EiEPNSTqXfZ3FKddo8NzeXdevWkZKSgslkonnz5lx22WXlGmBFM5kgJSWX\nHTsszJ5tp2XLgtObIucyeXIQmzZZ6dIln6FDL7zjOjgYbr/dye23OzlwoORBbtdd5+L996289ZaV\nY8cKqvPVVxdcjnb77fmEB94MkyJyDqVqeT/00EPUrFmT66+/HsMw2LhxI8ePH2fGjBkVESPgueu8\nt24106VLKNWqGXz0UXaFjAQ+Td88/cOfc3r7bSuDB4dwxRUuVqzILvfruN3ugglUliyx8cEHVvLy\n/mh616hR0Efeu3c+V1xR9puEBPp7FUgCMS/lVPp9FqdULe+MjAxmzZpVuNyuXTv69u1bPpF5WYsW\nbh59NI+JE4MZPDiYN9/MwaJB6FKMnTvNPPRQMOHhBgsX5nhkApbiBrnt2GEmPt5FfLwTm638jyki\n/qfU06Pm5OQQEhICQHZ2Nnl5eR4NrCINHJjPp59aWLnSxqxZdsaO9d+R9OIZmZlw770h5OSYWLQo\nh8su8/wZmtOD3ERE/qpUxbtXr1506tSJpk2bAgU3GhkxYoRHA6tIp/u/4+IszJhh54YbXNx0k/q/\npYDbDYMHh7B/v5mHHsqjUyddniAi3lWqsandu3dnyZIl3H777XTr1o033niDvXv3ejq2ChURAc8/\nX3DK/IEHgjl82AtzWYpPeuwxWLvWSvv2Tp2VERGfUOoLS2rXrk1cXByxsbHUrFmTr776ypNxecXV\nV7uZMCGP9HQzQ4YE41Lju9JbtcrC5MlwySVunn1W4yFExDdc8B17SzFI3S8NHpxPhw5OPv7Yypw5\ndm+HI160b5+JIUNCCAmBl1/O0e0yRcRnXHDxNnnjFkkVwGSCuXNzqFvXzfTpdj79VE2tyigrq2CA\n2smTJp5/Hpo2LfulWSIi5eWsA9batGlTbJE2DIPjx497LChvO93/3bVraOH851FRgXmmQc5kGDBq\nVDC7d1u4/34Hd99t1923RMSnnLV4v/766xUVh8+59lo3iYl5TJ4czJAhwaSm5pzX1JPiv5591sa7\n79q44QYnkyblAeo+ERHfctbiXbdu3YqKwycNGZLPxo1W1qyxkpJiZ9QojTQOdB9/bGHy5CBq1nTz\nwgu5mhRFRHyS2pJnYTbDvHm51Knj5skn7WzapP7vQPbLLyYGDgzGYoGXXsqp0KlyRUTOh4r3OVSv\nbrBgQS4mEwwaFExGRmAO1KvscnOhf/8Qjh41M2VKHtdeqwFqIuK7VLxL4frrXYwf7+DQITNDhwbj\n1ud6wElMDGLbNgsJCfnce6+mJBUR36biXUrDhjlo397JRx9ZmTdPA5gCySuv2Hj1VTvNmrl48slc\nAvQqSBEJICrepWQ2w9NP51Krlptp0+x89pn6vwPBl1+aGT8+iMhINwsX5vD7vXdERHyaivd5qFHD\n4PnnczGMgv7vo0fVRPNnR46Y6N8/BKcTnnsul3r1NEBNRPyDivd5uuEGF+PGOTh40MywYer/9ldO\nJwwcGMzBg2YSEx20bauJ7EXEf5TqlqBS1PDhDjZutLB2rZX58+08+KCu//YEw4A1ayx89JEVsxks\nFrDZDKxW/vRTsGyznX4cLBYDm63oc04/fnpdWpqVjRut3Hprvt4/EfE7Kt4XwGyG+fNzad8+lORk\nO9dd5+L669VyKy+GAStXWpk5085XX3lubMHll7uYO1cD1ETE/6h4X6CoqILrv++4I4RBg4JZt+4U\nkZHlt//cXPjpJzM//GDCZIJ27VwBP9uX2w3LlxcU7Z07LZhMBt265dO/fz6hoQZOJ7//mHA6IT8f\nXC7Izzf9/i9FnvPH4+BymYo8brFA3775hIV5O2sRkfPn0eKdnJzM9u3bMZlMJCYm0qxZs8LHli5d\nyltvvYXZbKZx48YkJSX53Z3K/vlPFw8/7GDatCAefDCEV145v/nPs7Phm2/M/PBDQZH+4QczP/5Y\nsPzLLyYM44/Xo04dN/3759Ovn4OLLvJAMl7kdsN//lNQtHftsmA2G9x5Zz6jRjlo1EiDCkRE/spj\nxXvz5s3s37+f1NRUvv/+exITE0lNTQUgJyeHDz74gNdeew2bzUa/fv3Ytm0bLVq08FQ4HjNiREH/\n9+rVVpo1q8LRoyYaNXIzcqSDbt2cZGVRpCjv22f6vVibOXQIoMoZ+6xd203Lli4aNHDToIHBwYMm\nliyxMWVKELNm2enVK5+BAx00bOjfo6NdLnj3XSuzZ9v59lsLFotBz575jBqV5/e5iYh4kseK96ZN\nm4iLiwOgYcOGnDhxgqysLMLCwggJCWHRokVAQSHPysoiKirKU6F4lMUCXbrks2GDlSNHCprdu3ZZ\nGDQohLFjDX777cyzCSaTwcUXG8TGQt26jsIi3aCBm/r13YSGnnmccePyePVVG//+t52FCwt+4uOd\nDBrk4KabXH7Vb+t0wrJlBUV7796Cot2nj4Phwx1ceqmKtojIuXiseGdkZBATE1O4HBkZSXp6OmF/\n6mR8/vnnWbx4Mf369aNevXqeCsXjXnqp+BnXcnKgXTvn78XZXVikL7nETVAQREWFk56eV6pjVKsG\nQ4fmM2hQPsuXW3nuOTurV1tZvdpKkyYuBg0qaOkHB5dnZuXL6YS33rIyZ04Q+/aZsVoN+vYtKNr1\n66toi4iUlskwDI98ak6cOJE2bdoUtr579+5NcnIyDRo0KPK83Nxc7r//fkaOHMnVV19d4v6cThdW\nq2/Oama1FpwCLm59vgenyf78c5g9G956q+D40dEwZAg88ADUrOm5456v/HxYvBiSk2HfvoLLuQYM\ngHHjoH59b0cnIuJ/PNbyjo6OJiMjo3D5yJEjhafGMzMz+e6777j22msJDg6mdevWbN269azF+/jx\nbE+FWmaNGoWya9eZXywaNXKRnl5y3AUt75MXfNxLL4V58+CRR0y89JKNV16xM2mSieRkgzvvLDil\n3qRJxQ74+nNODge88YaNlBQ7Bw6YsdsN+vcvuK66bt2C74zp6RUa3gUp6/vkqwIxr0DMCQIzL+VU\n+n0Wx2MzrLVq1YpVq1YBsHPnTqKjowtPmTudTsaNG8epU6cA+Prrr89okfuTkSOLn+RjxIiKmfzj\n4osNHn3UwbZtWTzxRC516xosWWKjbdsq3HlnCKtXWyp0Jri8PFi40Mb111dhzJhg0tNN3H+/gy1b\nTjFtWl5h4RYRkQvjsZZ3ixYtiImJISEhAZPJRFJSEmlpaYSHhxMfH8/QoUPp168fVquVK664gtjY\nWE+F4nHdujmBHFJS7OzZY6ZRIzcjRjh+X19xwsJgwIB87rsvn9WrLSxYYOfjj618/LGVyy5zcf/9\n+fTsmU+VMwe4l4vs7IIzAU88UYWDB82EhBg88ICDoUMd1Kypgi0iUl481udd3gLt9ApUzGmjr782\n88ILdtLSrDgcJi66qGCQ2IAB+VSvbnDqFGRlmX7/gVOnCn4/vb5g+czfTz/nz+scjoIh76GhBvfd\nl8/gwQ6io/3iz+usAvH0HgRmXoGYEwRmXsqp9Pssjoq3F1XkH+/hwyZeftnGokU2MjLK3ltisRiE\nhUFYmEFYmEGVKlClisFNN1m5++4satTwiz+rUgnEDxkIzLwCMScIzLyUU+n3WRxNj1pJ1Kxp8Mgj\nDkaMcJCWZiUtrWCu1YLiy+8F+MyCXPTfPx4PCqLYa8sL/ngDp3CLiPgiFe9KJjgY+vRx0qdPxfbH\ni4hI+dH9vEVERPyMireIiIifUfEWERHxMyreIiIifkbFW0RExM+oeIuIiPgZFW8RERE/o+ItIiLi\nZ1S8RURE/IyKt4iIiJ9R8RYREfEzKt4iIiJ+RsVbRETEz6h4i4iI+BkVbxERET+j4i0iIuJnVLxF\nRET8jIq3iIiIn1HxFhER8TMq3j5s2TIrbdqEUrt2GG3ahLJsmdXbIYmIiA9QNfBRy5ZZGTQopHB5\n1y7L78s5dOvm9F5gIiLidWp5+6g5c+zFrk9JKX69iIhUHirePmrPnuLfmpLWi4hI5aFK4KMaNXKf\n13oREak8VLx91MiRjmLXjxhR/HoREak8PDpgLTk5me3bt2MymUhMTKRZs2aFj3322WfMmjULs9lM\ngwYNmDp1KmazvkucVjAoLYeUFDt79php1MjNiBEODVYTERHPFe/Nmzezf/9+UlNT+f7770lMTCQ1\nNbXw8UcffZTFixdTq1Ythg8fzscff0ybNm08FY5f6tbNqWItIiJn8FhTd9OmTcTFxQHQsGFDTpw4\nQVZWVuHjaWlp1KpVC4DIyEiOHz/uqVBEREQCisda3hkZGcTExBQuR0ZGkp6eTlhYGEDhv0eOHOHT\nTz9lxIgRZ91fREQoVqvFU+F6TVRUuLdDKHfKyX8EYl6BmBMEZl7K6cJV2CQthmGcse7o0aM88MAD\nJCUlERERcdbtjx/P9lRoXhMVFU56+klvh1GulJP/CMS8AjEnCMy8lFPp91kcj502j46OJiMjo3D5\nyJEjREVFFS5nZWVx//33M3LkSG688UZPhSEiIhJwPFa8W7VqxapVqwDYuXMn0dHRhafKAaZNm8Y9\n99xD69atPRWCiIhIQPLYafMWLVoQExNDQkICJpOJpKQk0tLSCA8P58Ybb+Sdd95h//79vPXWWwDc\neuut9OrVy1PhiIiIBAyP9nmPGTOmyHLjxo0Lf9+xY4cnDy0iIhKwNCuKiIiIn1HxroR0n3AREf+m\nT+1KRvcJFxHxf2p5VzK6T7iIiP9T8a5kdJ9wERH/p0/sSkb3CRcR8X8q3pWM7hMuIuL/VLwrmW7d\nnCxYkEOTJi6sVoMmTVwsWKDBaiIi/kSjzSsh3SdcRMS/qeUtIiLiZ1S8RURE/IyKt4iIiJ9R8RYR\nEfEzKt5SLk7Pl261ovnSRUQ8TJ+wUmaaL11EpGKp5S1lpvnSRUQqloq3lJnmSxcRqVj6dJUy03zp\nIiIVS8VbykzzpYuIVCwVbymzovOlo/nSRUQ8TKPNpVycni89Kiqc9PRsb4cjIhLQ1PIWERHxMyre\nIiIifkbFW3zW6VnbatcO06xtIiJ/ok9D8UmatU1EpGRqeYtP0qxtIiIlU/EWn6RZ20RESqZPQvFJ\nmrVNRKRkHi3eycnJ9OrVi4SEBL766qsij+Xl5fHII49wxx13eDIE8VOatU1EpGQeK96bN29m//79\npKamMnXqVKZOnVrk8aeeeoorr7zSU4cXP1d01jajXGdt0yh2EfF3HvvU2rRpE3FxcQA0bNiQEydO\nkJWVRVhYGACjRo0iMzOT9957z1MhiJ87PWtbedIodhEJBB4r3hkZGcTExBQuR0ZGkp6eXli8w8LC\nyMzMLPX+IiJCsVot5R6nt0VFhXs7hHLnyzk9/XTx6+fPD2HgwJK38+WcyiIQ8wrEnCAw81JOF67C\nzhcahlGm7Y8fD7z5sgvmAT/p7TDKla/n9M03YYCpmPUG6elZxW7j6zldqEDMKxBzgsDMSzmVfp/F\n8Vifd3R0NBkZGYXLR44cISoqylOHEykVjWIXkUDgseLdqlUrVq1aBcDOnTuJjo4uPGUu4i0axS4i\ngcBjp81btGhBTEwMCQkJmEwmkpKSSEtLIzw8nPj4eIYPH86hQ4f44Ycf6Nu3Lz179qRLly6eCkcE\n4PdBaTmkpNjZs8dMo0ZuRoxwaLCaiPgVk1HWzugKEmh9I6A+H39RmpyWLbMyZ84fXwhGjvT9LwSV\n9b3yR4GYl3Iq/T6LowtcRcpIl5+JSEXT9KgiZaSbqIhIRVPxFikj3URFRCqaPl1EykiXn4lIRVPx\nFikjT11+pjnYRaQk+jQQKSNPXH6mQXAicjYq3iLloLxvonK2QXAq3iKi0+YiPkiD4ETkbPRJIOKD\nPDkI7nRfutWK+tJF/JSKt4gP8uQguEGDQti1y4LL9Udfugq4iH9R8RbxQd26OVmwIIcmTVxYrQZN\nmrhYsKDsg9U0oYxIYNDXbREfVd6D4EB96SKBQv9jRSoRT/Wl65p0kYql4i1SiXiiL71oP7pJ/egi\nFUDFW6QSKdqXTrn0pXuqH12teZGS6X+DSCVzui+94N7D2WXenyf60TXDnMjZqeUtImXiiX50jYoX\nOTsVbxEpE0/0o2tUvMjZ6X+CiJSJJ65Jr4gZ5tSXLv5MxVtEyqxbNyfr12fz669ZrF+fXeZ+6YqZ\nYa78RsbrC4FUNBVvEfE5/jTDnC6VE29Q8RYRn1TerXnwTF+6JwfX6SYyUhIVbxGpNDzRl+6pwXW6\niYycjYq3iFQanuhL99TgOn+a/EZ9/hVPxVtEKg1P9KV7anCdJye/Kc/+efX5e4eKt4hUKuXdl+6p\nwXX+MvlNRfT5q0V/JhVvEZEy8sTgOn+Z/KZi+vx9+7I+bwwsVPEWEfFBnriJjCda8/7U5+/5boOK\nG1jo0eKdnJxMr169SEhI4Kuvviry2MaNG+nevTu9evVi/vz5ngxDRMQvnW7R5+fjs5Pf+FOfv791\nG5yNx4r35s2b2b9/P6mpqUydOpWpU6cWeXzKlCnMmzePJUuW8Omnn7J3715PhSIiInimf96f+vz9\nqdvgXDzWrt+0aRNxcXEANGzYkBMnTpCVlUVYWBgHDhygWrVq1K5dG4A2bdqwadMmLrvsMk+FIyIi\n/HFLWF/f58iRjiK3hT2trJf17dplKXa9L+2zNDxWvDMyMoiJiSlcjoyMJD09nbCwMNLT04mMjCzy\n2IEDB866v4iIUKzWM18gfxcVFe7tEMqdcvIfgZhXIOYEgZnX2XIaOBCqVoUnnoBvvoEmTWD8eEhI\nOLOgl9ajj0Lv3meunzjRcsGvryf2WRoVNu7eMIwybX/8eHY5ReI7oqLCSU8/6e0wypVy8h+BmFcg\n5gSBmVdpcoqNLfj5s/T0Cz9mbCwsWGAlJcXOnj1mGjVyM2KEg9hY5wXvt+g+LTRq5CrzPv+spC8A\nHive0dHRZGRkFC4fOXKEqKioYh87fPgw0dHRngpFREQE8Gy3QcEXkoppaHqsR71Vq1asWrUKgJ07\ndxIdHU1YWBgAF198MVlZWfz88884nU4++ugjWrVq5alQREREAorHWt4tWrQgJiaGhIQETCYTSUlJ\npKWlER4eTnx8PJMmTWL06NEAdO7cmQYNGngqFBERkYDi0T7vMWPGFFlu3Lhx4e/XXnstqampnjy8\niIhIQNIMayIiIn5GxVtERMTPqHiLiIj4GRVvERERP6PiLSIi4mdUvEVERPyMySjrvKUiIiJSodTy\nFhER8TMq3iIiIn5GxVtERMTPqHiLiIj4GRVvERERP6PiLSIi4mc8elcxKfDUU0/x5Zdf4nQ6GTRo\nEDfffHPhY+3bt6dWrX8R1WMAAAn7SURBVFpYLBYAZsyYQc2aNb0Vaql8/vnnjBgxgssvvxyARo0a\nMXHixMLHN27cyKxZs7BYLLRu3ZqhQ4d6K9Tz8uabb/Lee+8VLu/YsYNt27YVLsfExNCiRYvC5Zdf\nfrnwffNFe/bsYciQIdx7773cfffdHDx4kIcffhiXy0VUVBTTp0/HbrcX2SY5OZnt27djMplITEyk\nWbNmXoq+eMXlNH78eJxOJ1arlenTpxMVFVX4/HP9rfqCv+Y0btw4du7cyUUXXQTAgAEDaNu2bZFt\nfP19gjPzGj58OMePHwcgMzOT5s2b8/jjjxc+Py0tjZSUFC655BIA/vnPfzJ48GCvxF6Sv36W//3v\nf/fe/ylDPGrTpk3G//3f/xmGYRjHjh0z2rRpU+Txdu3aGVlZWV6I7MJ99tlnxoMPPlji4506dTJ+\n/fVXw+VyGb179za+++67CoyufHz++efGpEmTiqy77rrrvBTN+Tt16pRx9913GxMmTDBeeeUVwzAM\nY9y4ccby5csNwzCMmTNnGq+99lqRbT7//HNj4MCBhmEYxt69e42ePXtWbNDnUFxODz/8sPHBBx8Y\nhmEYr776qvHkk08W2eZcf6veVlxOjzzyiLFu3boSt/H198kwis/rz8aNG2ds3769yLq3337bmDZt\nWkWFeN6K+yz35v8pnTb3sGuvvZaUlBQAqlatSk5ODi6Xy8tRec6BAweoVq0atWvXxmw206ZNGzZt\n2uTtsM7b/PnzGTJkiLfDuGB2u50XXniB6OjownWff/45sbGxALRr1+6M92XTpk3ExcUB0LBhQ06c\nOEFWVlbFBX0OxeWUlJREhw4dAIiIiCAzM9Nb4V2Q4nI6F19/n+Dsee3bt4+TJ0/65NmCsynus9yb\n/6dUvD3MYrEQGhoKwFtvvUXr1q3PONWalJRE7969mTFjBoafTHi3d+9eHnjgAXr37s2nn35auD49\nPZ3IyMjC5cj/b+9+Y2p8/wCOv08d4qShktCQfykzCin9o60tWWQxtSWzPEGlHKU21fGAyswsNiqx\niYq1mTRW09hqiKWFstmYKQ/SHxPGcsr3wZmz0un7y8+Xc+76vJ51X6dzrmvXdd+f+/pz35e9PR0d\nHebI4v/tyZMnzJgxY9DwK0Bvby9arZaoqCguXLhgptyNjFqtZsKECYOOffnyxTik5+DgMKReOjs7\nmTp1qvFvS6s7U2XSaDRYW1vT19dHSUkJ4eHhQ/5vuLZqCUyVCeDSpUvExsaSnJxMd3f3oDRLrycY\nvlwAFy9eJCYmxmTaw4cPiYuLY8eOHbS0tPzJLP4yU9dyc55TMuf9l9y+fZvy8nLOnz8/6HhiYiIB\nAQFMnjyZvXv3UlVVRWhoqJlyOTJz584lPj6e9evX09raSmxsLNXV1UPmepSqvLyczZs3DzmemprK\nxo0bUalUxMTEsHLlSpYuXWqGHP6+kdwkKuVGsq+vj9TUVHx8fPD19R2UpsS2umnTJqZMmYK7uzsF\nBQWcPn2azMzMYT+vlHoCww1wQ0MDOp1uSNqyZcuwt7dn7dq1NDY2cvDgQW7cuPH3M/k/DLyWD1y/\n9LfPKel5/wW1tbWcPXuWwsJC7OzsBqVFRETg4OCAWq0mMDCQFy9emCmXIzd9+nTCwsJQqVTMnj0b\nR0dH2tvbAXBycqKzs9P42fb29l8aErQE9fX1eHp6DjkeHR2Nra0tGo0GHx8fRdTVQBqNhq9fvwKm\n6+Xnunv37t2Q0QdLlJ6ezpw5c4iPjx+S9m9t1VL5+vri7u4OGBa0/tzOlFpPAI8ePRp2uHz+/PnG\nhXmenp50d3db3BTjz9dyc55TErz/sI8fP3Ls2DHy8/ONq0cHpsXFxdHb2wsYGvaPVbGWrKKigqKi\nIsAwTN7V1WVcIe/i4sKnT59oa2tDr9dz584d/Pz8zJndX9Le3o6tre2QntmrV6/QarV8//4dvV7P\n48ePFVFXA61Zs4aqqioAqqurCQgIGJTu5+dnTG9ubsbJyYlJkyb99Xz+ioqKCsaNG0diYuKw6cO1\nVUuVkJBAa2srYLiR/LmdKbGefnj69CmLFy82mVZYWEhlZSVgWKlub29vUU9zmLqWm/OckmHzP+zm\nzZu8f/+epKQk47HVq1fj5uZGSEgIgYGBbNu2DRsbGzw8PCx+yBwMvYEDBw5QU1PDt2/f0Ol0VFZW\nYmdnR0hICDqdDq1WC0BYWBiurq5mzvHI/TxnX1BQwKpVq/D09MTZ2ZktW7ZgZWVFcHCwRS+4efbs\nGbm5ubx9+xa1Wk1VVRXHjx8nLS2NK1euMHPmTCIiIgBITk4mOzsbLy8vlixZQlRUFCqViqysLDOX\nYjBTZerq6sLGxobt27cDht6bTqczlslUW7WkIXNTZYqJiSEpKYmJEyei0WjIzs4GlFNPYLpcp06d\noqOjw/go2A+7d+/mzJkzhIeHk5KSQllZGXq9niNHjpgp96aZupbn5ORw6NAhs5xTsiWoEEIIoTAy\nbC6EEEIojARvIYQQQmEkeAshhBAKI8FbCCGEUBgJ3kIIIYTCyKNiQoxibW1thIaGDnnpTFBQELt2\n7frt76+vr+fkyZOUlpb+9ncJIUZOgrcQo5y9vT3FxcXmzoYQ4j8kwVuIMcrDw4M9e/ZQX1/P58+f\nycnJYdGiRTQ1NZGTk4NarUalUpGZmcmCBQt4/fo1GRkZ9Pf3Y2NjY3x5SH9/P1lZWTx//pzx48eT\nn58PgFarpaenB71ez7p16yxub2YhlEzmvIUYo/r6+li4cCHFxcVER0eTl5cHGDZgSU9Pp7i4mJ07\nd3L48GHAsPtdXFwcly9fJjIyklu3bgHw8uVLEhISuHr1Kmq1mrq6Ou7du4der6ekpISysjI0Gg39\n/f1mK6sQo430vIUY5bq7u42vD/0hJSUFAH9/fwC8vLwoKiqip6eHrq4u46tfvb292b9/P2DYKtXb\n2xuADRs2AIY573nz5uHo6AiAs7MzPT09BAcHk5eXx759+wgKCmLr1q1YWUlfQYj/igRvIUa5f5vz\nHvh2ZJVKhUqlGjYdMNl7NrV5hIODA9evX6exsZGamhoiIyO5du3asHs8CyF+jdwKCzGGPXjwAICG\nhgbc3Nyws7Nj2rRpNDU1AXD//n2WL18OGHrntbW1gGGThhMnTgz7vXV1ddy9e5cVK1aQmpqKRqOh\nq6vrD5dGiLFDet5CjHKmhs1dXFwAaGlpobS0lA8fPpCbmwtAbm4uOTk5WFtbY2VlhU6nAyAjI4OM\njAxKSkpQq9UcPXqUN2/emPxNV1dX0tLSOHfuHNbW1vj7+zNr1qw/V0ghxhjZVUyIMcrNzY3m5mbU\narmHF0JpZNhcCCGEUBjpeQshhBAKIz1vIYQQQmEkeAshhBAKI8FbCCGEUBgJ3kIIIYTCSPAWQggh\nFEaCtxBCCKEw/wCluHY0xlz7PgAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 576x396 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"RLyOJH6s72fh","colab_type":"text"},"cell_type":"markdown","source":["## We can do the same with accuracy"]},{"metadata":{"id":"G3pihUCS72fi","colab_type":"code","outputId":"aed7f120-0bb3-466b-e16d-30cacde73310","executionInfo":{"status":"ok","timestamp":1554023729512,"user_tz":-120,"elapsed":71062,"user":{"displayName":"Ahmad El Sallab","photoUrl":"","userId":"06251939449358079201"}},"colab":{"base_uri":"https://localhost:8080/","height":376}},"cell_type":"code","source":["plt.clf()\n","acc_values = history_dict['binary_accuracy']\n","val_acc_values = history_dict['val_binary_accuracy']\n","plt.plot(epochs, acc_values, 'bo', label='Training acc')\n","plt.plot(epochs, val_acc_values, 'b', label='Validation acc')\n","plt.title('Training and validation accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()"],"execution_count":109,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAfUAAAFnCAYAAAC/5tBZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlDSJAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 576x396 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"6Ot-x-eT72fl","colab_type":"text"},"cell_type":"markdown","source":["## We are overfitting!\n","As you can see, the training loss decreases with every epoch, and the training accuracy\n","increases with every epoch. That’s what you would expect when running gradientdescent\n","optimization—the quantity you’re trying to minimize should be less with\n","every iteration. But that isn’t the case for the validation loss and accuracy: they seem to\n","peak at the fourth epoch. This is an example of what we warned against earlier: a\n","model that performs better on the training data isn’t necessarily a model that will do\n","better on data it has never seen before. In precise terms, what you’re seeing is overfitting:\n","after the second epoch, you’re overoptimizing on the training data, and you end\n","up learning representations that are specific to the training data and don’t generalize\n","to data outside of the training set."]},{"metadata":{"id":"tSIJIro_72fm","colab_type":"text"},"cell_type":"markdown","source":["__How to stop it__\n","\n","In this case, to prevent overfitting, you could stop training after three epochs. In\n","\n","general, you can use a range of techniques to mitigate overfitting, which we’ll cover later.\n","\n","Let's re-train again:\n","\n","__Important note__\n","In ipynb, you can't just call fit for epochs=3, because this will train over the last model!"]},{"metadata":{"id":"MT1OKNL072fn","colab_type":"code","outputId":"4241a077-3104-4923-8eb7-eb3ffc5f5a8d","executionInfo":{"status":"ok","timestamp":1554023744114,"user_tz":-120,"elapsed":85656,"user":{"displayName":"Ahmad El Sallab","photoUrl":"","userId":"06251939449358079201"}},"colab":{"base_uri":"https://localhost:8080/","height":418}},"cell_type":"code","source":["model = models.Sequential()\n","model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n","model.add(layers.Dense(16, activation='relu'))\n","model.add(layers.Dense(1, activation='sigmoid'))\n","model.compile(optimizer='rmsprop',\n","loss='binary_crossentropy',\n","metrics=['accuracy'])\n","print(model.summary())\n","model.fit(x_train, y_train, epochs=4, batch_size=512)\n","results = model.evaluate(x_test, y_test)\n","results"],"execution_count":110,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_41 (Dense)             (None, 16)                160016    \n","_________________________________________________________________\n","dense_42 (Dense)             (None, 16)                272       \n","_________________________________________________________________\n","dense_43 (Dense)             (None, 1)                 17        \n","=================================================================\n","Total params: 160,305\n","Trainable params: 160,305\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Epoch 1/4\n","25000/25000 [==============================] - 4s 140us/step - loss: 0.4737 - acc: 0.8219\n","Epoch 2/4\n","25000/25000 [==============================] - 3s 111us/step - loss: 0.2674 - acc: 0.9092\n","Epoch 3/4\n","25000/25000 [==============================] - 3s 112us/step - loss: 0.2034 - acc: 0.9281\n","Epoch 4/4\n","25000/25000 [==============================] - 3s 113us/step - loss: 0.1716 - acc: 0.9385\n","25000/25000 [==============================] - 2s 97us/step\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0.3110877853107452, 0.87612]"]},"metadata":{"tags":[]},"execution_count":110}]},{"metadata":{"id":"33g-EeAk72fp","colab_type":"text"},"cell_type":"markdown","source":["This fairly naive approach achieves an accuracy of 88%. With state-of-the-art\n","approaches, you should be able to get close to 95%."]},{"metadata":{"id":"s3v0gZbJ72fr","colab_type":"text"},"cell_type":"markdown","source":["# Inference\n","__Using a trained network to generate predictions on new data__\n"]},{"metadata":{"id":"zfED9pk272fr","colab_type":"code","colab":{}},"cell_type":"code","source":["out = model.predict(x_test)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"in9sHUogDz8h","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"outputId":"a836da23-c9cc-47a9-8f15-ee0cd9a03bde","executionInfo":{"status":"ok","timestamp":1554024225550,"user_tz":-120,"elapsed":1023,"user":{"displayName":"Ahmad El Sallab","photoUrl":"","userId":"06251939449358079201"}}},"cell_type":"code","source":["out[10]"],"execution_count":114,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.82113326], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":114}]},{"metadata":{"id":"Anx4Etei72fu","colab_type":"text"},"cell_type":"markdown","source":["# Further things to try:\n","The following experiments will help convince you that the architecture choices you’ve\n","made are all fairly reasonable, although there’s still room for improvement:\n","- You used two hidden layers. Try using one or three hidden layers, and see how\n","doing so affects validation and test accuracy.\n","- Try using layers with more hidden units or fewer hidden units: 32 units, 64 units,\n","and so on.\n","- Try using the mse loss function instead of binary_crossentropy.\n","- Try using the tanh activation (an activation that was popular in the early days of\n","neural networks) instead of relu."]},{"metadata":{"id":"MjUjRb5Q72fv","colab_type":"text"},"cell_type":"markdown","source":["# Example 2: Classifying newswires (Multi-class classification)\n"]},{"metadata":{"id":"pfwywOfM72fw","colab_type":"text"},"cell_type":"markdown","source":["# Example 3: Predicting house prices (Regression)"]}]}